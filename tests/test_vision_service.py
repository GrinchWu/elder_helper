"""VisionæœåŠ¡æµ‹è¯•è„šæœ¬ - æµ‹è¯•å±å¹•åˆ†æåŠŸèƒ½"""

from __future__ import annotations

import asyncio
import sys
import base64
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


async def test_screen_capture():
    """æµ‹è¯•å±å¹•æˆªå›¾åŠŸèƒ½"""
    from src.services.vision_service import VisionService, VLConfig
    
    print("=" * 70)
    print("æµ‹è¯•1: å±å¹•æˆªå›¾")
    print("=" * 70)
    
    config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(config)
    await vision.initialize()
    
    try:
        print("æ­£åœ¨æˆªå–å±å¹•...")
        screenshot, original_size = await vision.capture_screen()
        
        if screenshot:
            print(f"âœ… æˆªå›¾æˆåŠŸ! å¤§å°: {len(screenshot) / 1024:.1f} KB")
            print(f"   åŸå§‹å±å¹•å°ºå¯¸: {original_size[0]}x{original_size[1]}")
            
            # ä¿å­˜æˆªå›¾åˆ°æ–‡ä»¶
            output_path = Path(__file__).parent / "test_screenshot.png"
            with open(output_path, "wb") as f:
                f.write(screenshot)
            print(f"âœ… æˆªå›¾å·²ä¿å­˜åˆ°: {output_path}")
            
            return screenshot, original_size
        else:
            print("âŒ æˆªå›¾å¤±è´¥!")
            return None, (0, 0)
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None, (0, 0)
    finally:
        await vision.close()


async def test_screen_analysis(screenshot: bytes = None, original_size: tuple[int, int] = (0, 0)):
    """æµ‹è¯•å±å¹•åˆ†æåŠŸèƒ½"""
    from src.services.vision_service import VisionService, VLConfig
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•2: å±å¹•åˆ†æ")
    print("=" * 70)
    
    config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(config)
    await vision.initialize()
    
    try:
        # å¦‚æœæ²¡æœ‰ä¼ å…¥æˆªå›¾ï¼Œå…ˆæˆªå–
        if not screenshot:
            print("æ­£åœ¨æˆªå–å±å¹•...")
            screenshot, original_size = await vision.capture_screen()
        
        if not screenshot:
            print("âŒ æ— æ³•è·å–æˆªå›¾")
            return
        
        print(f"æˆªå›¾å¤§å°: {len(screenshot) / 1024:.1f} KB")
        print(f"åŸå§‹å±å¹•å°ºå¯¸: {original_size[0]}x{original_size[1]}")
        print("æ­£åœ¨åˆ†æå±å¹•å†…å®¹...")
        
        # åˆ†æå±å¹•ï¼ˆä¼ é€’åŸå§‹å°ºå¯¸ä»¥ä¾¿åæ ‡æ˜ å°„ï¼‰
        analysis = await vision.analyze_screen(screenshot, original_size=original_size)
        
        print("\nğŸ“Š åˆ†æç»“æœ:")
        print(f"  åº”ç”¨åç§°: {analysis.app_name or 'æœªè¯†åˆ«'}")
        print(f"  å±å¹•ç±»å‹: {analysis.screen_type or 'æœªè¯†åˆ«'}")
        print(f"  å±å¹•æè¿°: {analysis.description or 'æ— '}")
        
        if analysis.elements:
            print(f"\n  âœ… è¯†åˆ«åˆ° {len(analysis.elements)} ä¸ªå…ƒç´ :")
            for i, elem in enumerate(analysis.elements[:15], 1):  # æ˜¾ç¤ºå‰15ä¸ª
                clickable = "ğŸ–±ï¸" if elem.is_clickable else ""
                input_mark = "âŒ¨ï¸" if elem.is_input else ""
                print(f"    {i}. [{elem.element_type}] {elem.text or elem.description} {clickable}{input_mark}")
                if elem.bbox != (0, 0, 0, 0):
                    print(f"       ä½ç½®: {elem.bbox}")
            
            if len(analysis.elements) > 15:
                print(f"    ... è¿˜æœ‰ {len(analysis.elements) - 15} ä¸ªå…ƒç´ ")
        
        if analysis.suggested_actions:
            print(f"\n  ğŸ’¡ å»ºè®®æ“ä½œ:")
            for action in analysis.suggested_actions[:3]:
                print(f"    - {action}")
        
        if analysis.warnings:
            print(f"\n  âš ï¸ å®‰å…¨è­¦å‘Š:")
            for warning in analysis.warnings:
                print(f"    - {warning}")
        
        return analysis
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await vision.close()


async def test_screen_analysis_with_intent():
    """æµ‹è¯•å¸¦æ„å›¾çš„å±å¹•åˆ†æ"""
    from src.services.vision_service import VisionService, VLConfig
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•3: å¸¦æ„å›¾çš„å±å¹•åˆ†æ")
    print("=" * 70)
    
    config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(config)
    await vision.initialize()
    
    try:
        print("æ­£åœ¨æˆªå–å±å¹•...")
        screenshot, original_size = await vision.capture_screen()
        
        if not screenshot:
            print("âŒ æ— æ³•è·å–æˆªå›¾")
            return
        
        # æµ‹è¯•ä¸åŒçš„ç”¨æˆ·æ„å›¾
        intents = [
            "æˆ‘æƒ³æ‰“å¼€æµè§ˆå™¨ä¸Šç½‘",
            "æˆ‘æƒ³æ‰¾åˆ°å¾®ä¿¡",
            "æˆ‘æƒ³å†™ä¸ªæ–‡æ¡£",
        ]
        
        for intent in intents:
            print(f"\n{'='*50}")
            print(f"ç”¨æˆ·æ„å›¾: {intent}")
            print("-" * 50)
            
            analysis = await vision.analyze_screen(screenshot, user_intent=intent, original_size=original_size)
            
            print(f"å±å¹•æè¿°: {analysis.description[:100] if analysis.description else 'æ— '}...")
            
            if analysis.suggested_actions:
                print("å»ºè®®æ“ä½œ:")
                for action in analysis.suggested_actions[:2]:
                    print(f"  - {action}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await vision.close()


async def test_find_element():
    """æµ‹è¯•æŸ¥æ‰¾ç‰¹å®šå…ƒç´ """
    from src.services.vision_service import VisionService, VLConfig
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•4: æŸ¥æ‰¾ç‰¹å®šå…ƒç´ ")
    print("=" * 70)
    
    config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(config)
    await vision.initialize()
    
    try:
        print("æ­£åœ¨æˆªå–å±å¹•...")
        screenshot, original_size = await vision.capture_screen()
        
        if not screenshot:
            print("âŒ æ— æ³•è·å–æˆªå›¾")
            return
        
        # æµ‹è¯•æŸ¥æ‰¾ä¸åŒå…ƒç´ 
        elements_to_find = [
            "å¼€å§‹æŒ‰é’®",
            "æµè§ˆå™¨å›¾æ ‡",
            "æœç´¢æ¡†",
        ]
        
        for desc in elements_to_find:
            print(f"\næŸ¥æ‰¾: {desc}")
            element = await vision.find_element(screenshot, desc, original_size=original_size)
            
            if element:
                print(f"  âœ… æ‰¾åˆ°: [{element.element_type}] {element.text or element.description}")
                print(f"     ä½ç½®: {element.bbox}")
            else:
                print(f"  âŒ æœªæ‰¾åˆ°")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await vision.close()


async def test_with_image_file(image_path: str):
    """ä½¿ç”¨æŒ‡å®šå›¾ç‰‡æ–‡ä»¶æµ‹è¯•"""
    from src.services.vision_service import VisionService, VLConfig
    
    print("\n" + "=" * 70)
    print(f"æµ‹è¯•: åˆ†æå›¾ç‰‡æ–‡ä»¶ - {image_path}")
    print("=" * 70)
    
    config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(config)
    await vision.initialize()
    
    try:
        # è¯»å–å›¾ç‰‡æ–‡ä»¶
        with open(image_path, "rb") as f:
            screenshot = f.read()
        
        print(f"å›¾ç‰‡å¤§å°: {len(screenshot) / 1024:.1f} KB")
        print("æ­£åœ¨åˆ†æ...")
        
        analysis = await vision.analyze_screen(screenshot)
        
        print("\nğŸ“Š åˆ†æç»“æœ:")
        print(f"  åº”ç”¨åç§°: {analysis.app_name or 'æœªè¯†åˆ«'}")
        print(f"  å±å¹•ç±»å‹: {analysis.screen_type or 'æœªè¯†åˆ«'}")
        print(f"  å±å¹•æè¿°: {analysis.description or 'æ— '}")
        
        if analysis.elements:
            print(f"\n  è¯†åˆ«åˆ° {len(analysis.elements)} ä¸ªå…ƒç´ :")
            for i, elem in enumerate(analysis.elements[:10], 1):
                print(f"    {i}. [{elem.element_type}] {elem.text or elem.description}")
        
        if analysis.warnings:
            print(f"\n  âš ï¸ å®‰å…¨è­¦å‘Š:")
            for warning in analysis.warnings:
                print(f"    - {warning}")
        
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await vision.close()


async def interactive_test():
    """äº¤äº’å¼æµ‹è¯•"""
    from src.services.vision_service import VisionService, VLConfig
    
    print("=" * 70)
    print("äº¤äº’å¼Visionæµ‹è¯•")
    print("è¾“å…¥ 'quit' é€€å‡º")
    print("è¾“å…¥ 'capture' æˆªå–å¹¶åˆ†æå½“å‰å±å¹•")
    print("è¾“å…¥å…¶ä»–å†…å®¹ä½œä¸ºç”¨æˆ·æ„å›¾è¿›è¡Œåˆ†æ")
    print("=" * 70)
    
    config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(config)
    await vision.initialize()
    
    try:
        while True:
            user_input = input("\nè¯·è¾“å…¥ (capture/æ„å›¾/quit): ").strip()
            
            if user_input.lower() == 'quit':
                break
            
            if not user_input:
                continue
            
            print("\næ­£åœ¨æˆªå–å±å¹•...")
            screenshot, original_size = await vision.capture_screen()
            
            if not screenshot:
                print("âŒ æˆªå›¾å¤±è´¥")
                continue
            
            intent = "" if user_input.lower() == "capture" else user_input
            
            print("æ­£åœ¨åˆ†æ...")
            analysis = await vision.analyze_screen(screenshot, user_intent=intent, original_size=original_size)
            
            print(f"\nğŸ“Š åˆ†æç»“æœ:")
            print(f"  åº”ç”¨: {analysis.app_name or 'æœªè¯†åˆ«'}")
            print(f"  æè¿°: {analysis.description[:200] if analysis.description else 'æ— '}...")
            
            if analysis.suggested_actions:
                print(f"\n  å»ºè®®æ“ä½œ:")
                for action in analysis.suggested_actions[:3]:
                    print(f"    - {action}")
            
            if analysis.warnings:
                print(f"\n  âš ï¸ è­¦å‘Š: {analysis.warnings}")
                
    except KeyboardInterrupt:
        pass
    finally:
        await vision.close()
        print("\nå†è§ï¼")


def main():
    """ä¸»å‡½æ•°"""
    print("VisionæœåŠ¡æµ‹è¯•")
    print("=" * 70)
    print("1. å±å¹•æˆªå›¾æµ‹è¯•")
    print("2. å±å¹•åˆ†ææµ‹è¯•")
    print("3. å¸¦æ„å›¾çš„å±å¹•åˆ†æ")
    print("4. æŸ¥æ‰¾ç‰¹å®šå…ƒç´ ")
    print("5. äº¤äº’å¼æµ‹è¯•")
    print("6. åˆ†ææŒ‡å®šå›¾ç‰‡æ–‡ä»¶")
    print("7. è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    print("=" * 70)
    
    choice = input("è¯·é€‰æ‹©æµ‹è¯•é¡¹ (1-7): ").strip()
    
    if choice == "1":
        asyncio.run(test_screen_capture())
    elif choice == "2":
        asyncio.run(test_screen_analysis())
    elif choice == "3":
        asyncio.run(test_screen_analysis_with_intent())
    elif choice == "4":
        asyncio.run(test_find_element())
    elif choice == "5":
        asyncio.run(interactive_test())
    elif choice == "6":
        image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
        if image_path:
            asyncio.run(test_with_image_file(image_path))
    elif choice == "7":
        async def run_all():
            screenshot, original_size = await test_screen_capture()
            if screenshot:
                await test_screen_analysis(screenshot, original_size)
            await test_screen_analysis_with_intent()
            await test_find_element()
        asyncio.run(run_all())
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œå±å¹•åˆ†ææµ‹è¯•...")
        asyncio.run(test_screen_analysis())


if __name__ == "__main__":
    main()
