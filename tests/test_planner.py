"""ä»»åŠ¡è§„åˆ’æµ‹è¯•è„šæœ¬ - æµ‹è¯•é”®ç›˜è¾“å…¥éœ€æ±‚ + å±å¹•ç†è§£ + ä»»åŠ¡è§„åˆ’"""

from __future__ import annotations

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


async def test_planner_with_vision():
    """æµ‹è¯•ä»»åŠ¡è§„åˆ’ï¼šé”®ç›˜è¾“å…¥éœ€æ±‚ + å±å¹•ç†è§£ + ä»»åŠ¡è§„åˆ’"""
    from src.services.vision_service import VisionService, VLConfig
    from src.services.planner_service import PlannerService
    from src.models.intent import Intent, IntentType
    
    print("=" * 70)
    print("ä»»åŠ¡è§„åˆ’æµ‹è¯•")
    print("=" * 70)
    print("1. è¾“å…¥æ‚¨çš„éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼šæ‰“å¼€å¾®ä¿¡ã€æ‰“å¼€æµè§ˆå™¨æœç´¢å¤©æ°”ï¼‰")
    print("2. ç³»ç»Ÿä¼šæˆªå–å½“å‰å±å¹•å¹¶åˆ†æ")
    print("3. æ ¹æ®å±å¹•å†…å®¹å’Œéœ€æ±‚ç”Ÿæˆä»»åŠ¡è®¡åˆ’")
    print("è¾“å…¥ 'quit' é€€å‡º")
    print("=" * 70)
    
    # åˆå§‹åŒ–VisionæœåŠ¡
    vl_config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(vl_config)
    await vision.initialize()
    
    # åˆå§‹åŒ–PlanneræœåŠ¡
    planner = PlannerService()
    await planner.initialize()
    
    try:
        while True:
            print("\n" + "-" * 70)
            user_input = input("è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚: ").strip()
            
            if user_input.lower() == 'quit':
                print("å†è§ï¼")
                break
            
            if not user_input:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„éœ€æ±‚")
                continue
            
            # 1. æˆªå–å¹¶åˆ†æå½“å‰å±å¹•
            print("\nğŸ“¸ æ­£åœ¨æˆªå–å±å¹•...")
            screenshot, original_size = await vision.capture_screen()
            
            if not screenshot:
                print("âŒ æˆªå›¾å¤±è´¥")
                continue
            
            print(f"   å±å¹•å°ºå¯¸: {original_size[0]}x{original_size[1]}")
            
            print("\nğŸ” æ­£åœ¨åˆ†æå±å¹•å†…å®¹...")
            screen_analysis = await vision.analyze_screen(
                screenshot, 
                user_intent=user_input,
                original_size=original_size
            )
            
            # æ˜¾ç¤ºå±å¹•åˆ†æç»“æœ
            print("\nğŸ“Š å±å¹•åˆ†æç»“æœ:")
            print(f"   åº”ç”¨: {screen_analysis.app_name or 'æœªè¯†åˆ«'}")
            print(f"   ç±»å‹: {screen_analysis.screen_type or 'æœªè¯†åˆ«'}")
            print(f"   æè¿°: {screen_analysis.description[:100] if screen_analysis.description else 'æ— '}...")
            
            if screen_analysis.elements:
                print(f"\n   è¯†åˆ«åˆ° {len(screen_analysis.elements)} ä¸ªå…ƒç´ :")
                for i, elem in enumerate(screen_analysis.elements[:8], 1):
                    clickable = "ğŸ–±ï¸" if elem.is_clickable else ""
                    text = elem.text or elem.description
                    print(f"     {i}. [{elem.element_type}] {text[:25] if text else 'æ— '} {clickable}")
            
            # 2. åˆ›å»ºæ„å›¾å¯¹è±¡
            intent = Intent(
                raw_text=user_input,
                normalized_text=user_input,
                intent_type=IntentType.NAVIGATION,  # å¯¼èˆª/æ‰“å¼€åº”ç”¨
            )
            
            # 3. ç”Ÿæˆä»»åŠ¡è®¡åˆ’
            print("\nğŸ§  æ­£åœ¨ç”Ÿæˆä»»åŠ¡è®¡åˆ’...")
            plan = await planner.create_plan(
                intent=intent,
                screen_analysis=screen_analysis,
            )
            
            # æ˜¾ç¤ºä»»åŠ¡è®¡åˆ’
            print("\n" + "=" * 70)
            print("ğŸ“‹ ä»»åŠ¡è®¡åˆ’")
            print("=" * 70)
            
            if plan.steps:
                for step in plan.steps:
                    print(f"\næ­¥éª¤ {step.step_number}:")
                    print(f"  ğŸ“ æè¿°: {step.description}")
                    print(f"  ğŸ‘´ æŒ‡ä»¤: {step.friendly_instruction}")
                    if step.action:
                        print(f"  ğŸ¯ åŠ¨ä½œ: {step.action.action_type.value}")
                        if step.action.element_description:
                            print(f"  ğŸ”˜ ç›®æ ‡: {step.action.element_description}")
                        if step.action.text:
                            print(f"  âŒ¨ï¸ è¾“å…¥: {step.action.text}")
                    if step.expected_result:
                        print(f"  âœ… é¢„æœŸ: {step.expected_result}")
                    if step.error_recovery_hint:
                        print(f"  âš ï¸ å‡ºé”™å¤„ç†: {step.error_recovery_hint}")
            else:
                print("âŒ æœªèƒ½ç”Ÿæˆä»»åŠ¡è®¡åˆ’")
            
            print("\n" + "=" * 70)
            
    except KeyboardInterrupt:
        print("\n\nå·²ä¸­æ–­")
    finally:
        await vision.close()
        await planner.close()


async def test_react_mode():
    """æµ‹è¯•ReActæ¨¡å¼çš„ä»»åŠ¡è§„åˆ’"""
    from src.services.vision_service import VisionService, VLConfig
    from src.services.planner_service import PlannerService, PlannerContext
    from src.models.intent import Intent, IntentType
    
    print("=" * 70)
    print("ReActæ¨¡å¼ä»»åŠ¡è§„åˆ’æµ‹è¯•")
    print("=" * 70)
    print("ReActæ¨¡å¼ä¼šé€æ­¥æ€è€ƒå’Œæ‰§è¡Œï¼Œæ¯ä¸€æ­¥éƒ½ä¼šè§‚å¯Ÿç»“æœ")
    print("è¾“å…¥ 'quit' é€€å‡º")
    print("=" * 70)
    
    # åˆå§‹åŒ–æœåŠ¡
    vl_config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(vl_config)
    await vision.initialize()
    
    planner = PlannerService()
    await planner.initialize()
    
    try:
        while True:
            print("\n" + "-" * 70)
            user_input = input("è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚: ").strip()
            
            if user_input.lower() == 'quit':
                print("å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            # æˆªå–å±å¹•
            print("\nğŸ“¸ æ­£åœ¨æˆªå–å±å¹•...")
            screenshot, original_size = await vision.capture_screen()
            
            if not screenshot:
                print("âŒ æˆªå›¾å¤±è´¥")
                continue
            
            print("ğŸ” æ­£åœ¨åˆ†æå±å¹•...")
            screen_analysis = await vision.analyze_screen(
                screenshot,
                user_intent=user_input,
                original_size=original_size
            )
            
            # åˆ›å»ºæ„å›¾å’Œä¸Šä¸‹æ–‡
            intent = Intent(
                raw_text=user_input,
                normalized_text=user_input,
                intent_type=IntentType.NAVIGATION,
            )
            
            context = PlannerContext(
                intent=intent,
                current_screen=screen_analysis,
                max_steps=10,
            )
            
            # ReActå¾ªç¯
            print("\n" + "=" * 70)
            print("ğŸ¤– ReActæ¨ç†è¿‡ç¨‹")
            print("=" * 70)
            
            for step_num in range(context.max_steps):
                print(f"\n--- ç¬¬ {step_num + 1} æ­¥ ---")
                
                # è·å–ä¸‹ä¸€æ­¥å»ºè®®
                react_step = await planner.suggest_next_action(context)
                
                print(f"ğŸ’­ æ€è€ƒ: {react_step.thought}")
                
                if react_step.action:
                    print(f"ğŸ¯ åŠ¨ä½œ: {react_step.action.action_type.value}")
                    if react_step.action.element_description:
                        print(f"   ç›®æ ‡: {react_step.action.element_description}")
                    if react_step.action.text:
                        print(f"   è¾“å…¥: {react_step.action.text}")
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if react_step.action.action_type.value == "confirm":
                        print("\nâœ… ä»»åŠ¡è§„åˆ’å®Œæˆï¼")
                        break
                
                # æ¨¡æ‹Ÿè§‚å¯Ÿï¼ˆå®é™…åº”è¯¥æ‰§è¡ŒåŠ¨ä½œåè§‚å¯Ÿï¼‰
                react_step.observation = "ç­‰å¾…æ‰§è¡Œ..."
                context.history.append(react_step)
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­
                cont = input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€æ­¥ï¼Œè¾“å…¥'stop'åœæ­¢: ").strip()
                if cont.lower() == 'stop':
                    break
            
            print("\n" + "=" * 70)
            
    except KeyboardInterrupt:
        print("\n\nå·²ä¸­æ–­")
    finally:
        await vision.close()
        await planner.close()


async def test_quick_plan():
    """å¿«é€Ÿæµ‹è¯•ï¼šåªç”Ÿæˆè®¡åˆ’ï¼Œä¸è¿›å…¥äº¤äº’æ¨¡å¼"""
    from src.services.vision_service import VisionService, VLConfig
    from src.services.planner_service import PlannerService
    from src.models.intent import Intent, IntentType
    
    print("=" * 70)
    print("å¿«é€Ÿä»»åŠ¡è§„åˆ’æµ‹è¯•")
    print("=" * 70)
    
    # é¢„è®¾çš„æµ‹è¯•éœ€æ±‚
    test_requests = [
        "æ‰“å¼€å¾®ä¿¡",
        "æ‰“å¼€æµè§ˆå™¨æœç´¢ä»Šå¤©çš„å¤©æ°”",
        "æ‰“å¼€è®°äº‹æœ¬å†™ä¸€æ®µæ–‡å­—",
    ]
    
    print("æµ‹è¯•éœ€æ±‚:")
    for i, req in enumerate(test_requests, 1):
        print(f"  {i}. {req}")
    
    choice = input("\nè¯·é€‰æ‹© (1-3) æˆ–è¾“å…¥è‡ªå®šä¹‰éœ€æ±‚: ").strip()
    
    if choice in ["1", "2", "3"]:
        user_request = test_requests[int(choice) - 1]
    else:
        user_request = choice
    
    print(f"\né€‰æ‹©çš„éœ€æ±‚: {user_request}")
    
    # åˆå§‹åŒ–æœåŠ¡
    vl_config = VLConfig(
        api_key="CL9TPTG2Qro1oto8pSyBq6bQpXFCRs8g-Yl2d7nuElQBr2HtqkA19yu7wC1Zy6DGWOe4BELfLoZXUfuhD3yIoQ",
        model="Qwen3-VL-235B-A22B-Instruct",
    )
    
    vision = VisionService(vl_config)
    await vision.initialize()
    
    planner = PlannerService()
    await planner.initialize()
    
    try:
        # æˆªå–å¹¶åˆ†æå±å¹•
        print("\nğŸ“¸ æˆªå–å±å¹•...")
        screenshot, original_size = await vision.capture_screen()
        
        if not screenshot:
            print("âŒ æˆªå›¾å¤±è´¥")
            return
        
        print(f"   å°ºå¯¸: {original_size[0]}x{original_size[1]}")
        
        print("\nğŸ” åˆ†æå±å¹•...")
        screen_analysis = await vision.analyze_screen(
            screenshot,
            user_intent=user_request,
            original_size=original_size
        )
        
        print(f"   åº”ç”¨: {screen_analysis.app_name or 'æœªè¯†åˆ«'}")
        print(f"   å…ƒç´ æ•°: {len(screen_analysis.elements)}")
        
        # åˆ›å»ºæ„å›¾
        intent = Intent(
            raw_text=user_request,
            normalized_text=user_request,
            intent_type=IntentType.NAVIGATION,
        )
        
        # ç”Ÿæˆè®¡åˆ’
        print("\nğŸ§  ç”Ÿæˆä»»åŠ¡è®¡åˆ’...")
        plan = await planner.create_plan(
            intent=intent,
            screen_analysis=screen_analysis,
        )
        
        # æ˜¾ç¤ºè®¡åˆ’
        print("\n" + "=" * 70)
        print(f"ğŸ“‹ ä»»åŠ¡è®¡åˆ’: {user_request}")
        print("=" * 70)
        
        if plan.steps:
            for step in plan.steps:
                print(f"\nã€æ­¥éª¤ {step.step_number}ã€‘")
                print(f"  {step.friendly_instruction or step.description}")
                if step.action and step.action.element_description:
                    print(f"  â†’ ç‚¹å‡»: {step.action.element_description}")
        else:
            print("âŒ æœªèƒ½ç”Ÿæˆè®¡åˆ’")
        
    finally:
        await vision.close()
        await planner.close()


def main():
    """ä¸»å‡½æ•°"""
    print("ä»»åŠ¡è§„åˆ’æµ‹è¯•")
    print("=" * 70)
    print("1. äº¤äº’å¼ä»»åŠ¡è§„åˆ’ï¼ˆæ¨èï¼‰")
    print("2. ReActæ¨¡å¼æµ‹è¯•")
    print("3. å¿«é€Ÿæµ‹è¯•")
    print("=" * 70)
    
    choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()
    
    if choice == "1":
        asyncio.run(test_planner_with_vision())
    elif choice == "2":
        asyncio.run(test_react_mode())
    elif choice == "3":
        asyncio.run(test_quick_plan())
    else:
        print("é»˜è®¤è¿è¡Œäº¤äº’å¼ä»»åŠ¡è§„åˆ’...")
        asyncio.run(test_planner_with_vision())


if __name__ == "__main__":
    main()
