"""
æ™ºèƒ½åŠ©æ‰‹æ¡Œé¢åº”ç”¨ - ç®€æ´ç‰ˆ
é›†æˆè¯­éŸ³è¾“å…¥/è¾“å‡ºã€ä»»åŠ¡æ‰§è¡ŒåŠŸèƒ½
æ”¯æŒï¼šéœ€æ±‚å½•éŸ³ã€æé—®å½•éŸ³ã€é‡æ–°å¼€å§‹æµç¨‹
"""
import sys
import asyncio
import threading
from PyQt5.QtWidgets import (QApplication, QWidget, QHBoxLayout, QVBoxLayout,
                             QLabel, QPushButton, QLineEdit, QGraphicsDropShadowEffect)
from PyQt5.QtCore import Qt, QPoint, pyqtSignal, QObject
from PyQt5.QtGui import QFont, QColor, QPainter, QPainterPath, QBrush, QLinearGradient

from src.config import config
from src.models.intent import Intent
from src.models.task import Task, TaskStatus, TaskPlan
from src.models.session import UserProfile
from src.models.knowledge import KnowledgeGraph
from src.services.llm_service import LLMService
from src.services.vision_service import VisionService, VLConfig, ScreenAnalysis
from src.services.planner_service import PlannerService
from src.services.safety_service import SafetyService
from src.services.executor_service import ExecutorService
from src.services.embedding_service import EmbeddingService
from src.services.tts_service import TTSService
from src.services.asr_service import ASRService, ASRConfig, AudioCapture
from src.knowledge.rag_service import RAGService
from src.knowledge.video_extractor import VideoKnowledgeExtractor
from src.models.action import ActionType
from loguru import logger


class SignalBridge(QObject):
    """Qtä¿¡å·æ¡¥æ¥å™¨ï¼Œç”¨äºçº¿ç¨‹é—´é€šä¿¡"""
    status_changed = pyqtSignal(str)
    message_received = pyqtSignal(str)
    recording_done = pyqtSignal(str, str)  # (text, input_type)
    processing_done = pyqtSignal()
    reset_done = pyqtSignal()


class ElderlyAgent:
    """è€å¹´äººåŠ©æ‰‹Agent"""
    
    def __init__(self, signals: SignalBridge):
        self._signals = signals
        self._llm = None
        self._vision = None
        self._planner = None
        self._safety = None
        self._executor = None
        self._embedding = None
        self._rag = None
        self._knowledge_graph = None
        self._video_extractor = None
        self._tts = None
        self._asr = None
        self._audio_capture = None
        self._user_profile = None
        self._current_plan = None
        self._current_intent = None
        self._idle_timeout = 30
        self._last_action_time = None
        self._idle_check_task = None
        self._is_recording = False  # å½•éŸ³çŠ¶æ€

    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
        self._signals.status_changed.emit("åˆå§‹åŒ–è¯­éŸ³æœåŠ¡...")
        self._tts = TTSService()
        await self._tts.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«...")
        asr_config = ASRConfig(
            project_id=config.asr.project_id,
            easyllm_id=config.asr.easyllm_id,
            api_key=config.asr.api_key,
        )
        self._asr = ASRService(asr_config)
        await self._asr.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–æ„å›¾ç†è§£...")
        self._llm = LLMService()
        await self._llm.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è§†è§‰æœåŠ¡...")
        vl_config = VLConfig(
            api_key=config.api.api_key,
            model_light=config.api.vl_model_light,
            model_heavy=config.api.vl_model_heavy,
        )
        self._vision = VisionService(vl_config)
        await self._vision.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è§„åˆ’æœåŠ¡...")
        self._planner = PlannerService()
        await self._planner.initialize()
        
        self._safety = SafetyService()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–çŸ¥è¯†æœåŠ¡...")
        self._embedding = EmbeddingService()
        await self._embedding.initialize()
        
        self._knowledge_graph = KnowledgeGraph()
        self._rag = RAGService()
        await self._rag.initialize(
            embedding_service=self._embedding,
            knowledge_graph=self._knowledge_graph,
        )
        self._planner.set_rag_service(self._rag)
        
        # æ„å»ºçŸ¥è¯†åº“ï¼ˆä»Bç«™æœç´¢æˆ–ä½¿ç”¨é¢„ç½®æ•°æ®ï¼‰
        self._signals.status_changed.emit("æ„å»ºçŸ¥è¯†åº“...")
        self._video_extractor = VideoKnowledgeExtractor()
        await self._video_extractor.initialize()
        
        try:
            # ä½¿ç”¨å¸¦å›é€€çš„æ„å»ºæ–¹æ³•ï¼ˆå¦‚æœBç«™æœç´¢å¤±è´¥åˆ™ä½¿ç”¨é¢„ç½®æ•°æ®ï¼‰
            kb_stats = await self._video_extractor.build_knowledge_base_with_fallback(self._rag)
            logger.info(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆ: {kb_stats}")
        except Exception as e:
            logger.warning(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼Œä½¿ç”¨é¢„ç½®æ•°æ®: {e}")
            await self._video_extractor._load_preset_knowledge(self._rag)
        
        self._signals.status_changed.emit("åˆå§‹åŒ–æ‰§è¡ŒæœåŠ¡...")
        self._executor = ExecutorService()
        self._executor.set_vision_service(self._vision)
        self._executor.set_planner_service(self._planner)
        await self._executor.initialize()
        
        self._user_profile = UserProfile(
            name="ç”¨æˆ·",
            family_mapping={"è€äºŒ": "å¼ å°æ˜", "é—ºå¥³": "å¼ å°çº¢"},
            frequent_contacts=["å¼ å°æ˜", "å¼ å°çº¢"],
        )
        
        self._signals.status_changed.emit("å‡†å¤‡å°±ç»ª")
        await self._tts.speak_welcome()
        
        self._last_action_time = asyncio.get_event_loop().time()
        self._idle_check_task = asyncio.create_task(self._check_idle())

    async def _check_idle(self):
        """æ£€æµ‹ç”¨æˆ·æ˜¯å¦é•¿æ—¶é—´æ— åŠ¨ä½œ"""
        while True:
            await asyncio.sleep(5)
            if self._last_action_time:
                elapsed = asyncio.get_event_loop().time() - self._last_action_time
                if elapsed >= self._idle_timeout:
                    await self._tts.speak("æ‚¨å¥½ï¼Œéœ€è¦æˆ‘å¸®æ‚¨åšä»€ä¹ˆå—ï¼Ÿ")
                    self._last_action_time = asyncio.get_event_loop().time()
    
    def _reset_idle_timer(self):
        """é‡ç½®ç©ºé—²è®¡æ—¶å™¨"""
        self._last_action_time = asyncio.get_event_loop().time()

    async def close(self):
        """å…³é—­æœåŠ¡"""
        if self._idle_check_task:
            self._idle_check_task.cancel()
        for svc in [self._asr, self._tts, self._llm, self._vision, 
                    self._planner, self._executor, self._embedding, self._video_extractor]:
            if svc:
                await svc.close()

    async def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if self._is_recording:
            return
        self._is_recording = True
        self._reset_idle_timer()
        await self._tts.speak("å¼€å§‹å½•éŸ³ï¼Œè¯·è¯´è¯")
        self._audio_capture = AudioCapture(sample_rate=config.asr.sample_rate)
        self._audio_capture.start()
        logger.info("å½•éŸ³å·²å¼€å§‹")

    async def stop_recording(self, input_type: str = "requirement"):
        """åœæ­¢å½•éŸ³å¹¶è¯†åˆ«"""
        if not self._is_recording:
            self._signals.recording_done.emit("", input_type)
            return
        
        self._is_recording = False
        try:
            if self._audio_capture:
                audio_data = self._audio_capture.get_all_audio()
                self._audio_capture.stop()
                self._audio_capture = None
                
                if audio_data:
                    self._signals.status_changed.emit("è¯†åˆ«ä¸­...")
                    logger.info(f"éŸ³é¢‘æ•°æ®å¤§å°: {len(audio_data)} bytes")
                    result = await self._asr.recognize_audio(audio_data)
                    text = result.text.strip() if result.text else ""
                    if text:
                        logger.info(f"è¯†åˆ«ç»“æœ: {text}")
                        await self._tts.speak(f"æ‚¨è¯´çš„æ˜¯ï¼š{text}")
                    self._signals.recording_done.emit(text, input_type)
                else:
                    self._signals.recording_done.emit("", input_type)
        except Exception as e:
            logger.error(f"åœæ­¢å½•éŸ³å¤±è´¥: {e}")
            self._signals.recording_done.emit("", input_type)

    async def reset_flow(self):
        """é‡æ–°å¼€å§‹æµç¨‹"""
        self._current_plan = None
        self._current_intent = None
        self._reset_idle_timer()
        await self._tts.speak("å¥½çš„ï¼Œæˆ‘ä»¬é‡æ–°å¼€å§‹ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©")
        self._signals.reset_done.emit()
        logger.info("æµç¨‹å·²é‡ç½®")

    async def process_requirement(self, user_input: str):
        """å¤„ç†ç”¨æˆ·éœ€æ±‚ï¼ˆä¸»æµç¨‹ï¼‰- ä¼˜åŒ–ç‰ˆï¼šå¹¶è¡ŒåŒ– + æ··åˆè§„åˆ’æ¨¡å¼"""
        self._reset_idle_timer()
        try:
            self._signals.status_changed.emit("å®‰å…¨æ£€æŸ¥...")
            
            safety_result = self._safety.check_text_safety(user_input)
            if not safety_result.is_safe and safety_result.blocked_reason:
                await self._tts.speak(f"å®‰å…¨è­¦å‘Šï¼š{safety_result.blocked_reason}")
                self._signals.processing_done.emit()
                return
            
            # ========== å¹¶è¡Œæ‰§è¡Œï¼šæ„å›¾ç†è§£ + å±å¹•æˆªå›¾ + RAGæœç´¢ ==========
            self._signals.status_changed.emit("åˆ†æä¸­...")
            logger.info("=" * 50)
            logger.info("[å¹¶è¡Œå¤„ç†] å¼€å§‹å¹¶è¡Œæ‰§è¡Œï¼šæ„å›¾ç†è§£ + å±å¹•æˆªå›¾ + RAGæœç´¢")
            
            import time
            start_time = time.time()
            
            # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            intent_task = asyncio.create_task(
                self._llm.understand_intent(user_input, self._user_profile)
            )
            screenshot_task = asyncio.create_task(
                self._vision.capture_screen()
            )
            rag_task = asyncio.create_task(
                self._rag.retrieve(user_input, top_k=3)
            )
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            intent, (screenshot, original_size), rag_result = await asyncio.gather(
                intent_task, screenshot_task, rag_task,
                return_exceptions=True
            )
            
            parallel_time = time.time() - start_time
            logger.info(f"[å¹¶è¡Œå¤„ç†] å®Œæˆï¼Œè€—æ—¶: {parallel_time:.2f}s")
            
            # å¤„ç†å¯èƒ½çš„å¼‚å¸¸
            if isinstance(intent, Exception):
                logger.error(f"æ„å›¾ç†è§£å¤±è´¥: {intent}")
                await self._tts.speak("æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„æ€")
                self._signals.processing_done.emit()
                return
            
            if isinstance(screenshot, Exception) or not screenshot:
                logger.error(f"æˆªå±å¤±è´¥: {screenshot}")
                await self._tts.speak("æˆªå±å¤±è´¥")
                self._signals.processing_done.emit()
                return
            
            self._current_intent = intent
            logger.info(f"[æ„å›¾ç†è§£] åŸå§‹è¾“å…¥: {user_input}")
            logger.info(f"[æ„å›¾ç†è§£] è§„èŒƒåŒ–æ–‡æœ¬: {intent.normalized_text}")
            logger.info(f"[æ„å›¾ç†è§£] ç½®ä¿¡åº¦: {intent.confidence}")
            
            if intent.confidence.is_low:
                await self._tts.speak("æˆ‘ä¸å¤ªç¡®å®šæ‚¨æƒ³åšä»€ä¹ˆï¼Œèƒ½å†è¯´è¯¦ç»†ä¸€ç‚¹å—ï¼Ÿ")
                self._signals.processing_done.emit()
                return
            
            # RAGç»“æœæ—¥å¿—
            if not isinstance(rag_result, Exception) and (rag_result.guides or rag_result.nodes):
                logger.info(f"[RAGæœç´¢] æ‰¾åˆ° {len(rag_result.guides)} æ¡æŒ‡å—, {len(rag_result.nodes)} ä¸ªçŸ¥è¯†èŠ‚ç‚¹")
            else:
                logger.info("[RAGæœç´¢] æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
            
            # ========== å±å¹•åˆ†æï¼ˆéœ€è¦intentç»“æœï¼‰==========
            self._signals.status_changed.emit("åˆ†æå±å¹•...")
            screen_state = await self._vision.analyze_screen_state(
                screenshot, user_intent=intent.normalized_text or user_input
            )
            logger.info(f"[å±å¹•åˆ†æ] åº”ç”¨: {screen_state.app_name}")
            logger.info(f"[å±å¹•åˆ†æ] çŠ¶æ€: {screen_state.screen_state}")
            logger.info("=" * 50)
            
            screen_analysis = ScreenAnalysis(
                app_name=screen_state.app_name,
                screen_type=screen_state.screen_state,
                description=screen_state.description,
                suggested_actions=[screen_state.suggested_action] if screen_state.suggested_action else [],
                warnings=screen_state.warnings,
            )
            
            # ========== æ··åˆæ¨¡å¼ï¼šReActå¾ªç¯æ‰§è¡Œ ==========
            self._signals.status_changed.emit("æ‰§è¡Œä¸­...")
            await self._tts.speak("å¥½çš„ï¼Œæˆ‘æ¥å¸®æ‚¨æ“ä½œ")
            
            # ä½¿ç”¨ReActå¾ªç¯æ¨¡å¼
            await self._react_execution_loop(intent, screen_analysis, screenshot)
            
        except Exception as e:
            logger.error(f"å¤„ç†å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            await self._tts.speak_error(str(e))
            self._signals.status_changed.emit("å‡ºé”™")
        finally:
            self._reset_idle_timer()
            self._signals.processing_done.emit()
    
    async def _react_execution_loop(self, intent: Intent, screen_analysis: ScreenAnalysis, screenshot: bytes):
        """ReActå¾ªç¯æ‰§è¡Œæ¨¡å¼ - è§‚å¯Ÿ->è§„åˆ’->æ‰§è¡Œ->è§‚å¯Ÿ..."""
        max_steps = 10
        history = []
        current_screen = screen_analysis
        current_screenshot = screenshot
        
        for step_num in range(max_steps):
            self._reset_idle_timer()
            
            # 1. å¿«é€Ÿè§„åˆ’ä¸‹ä¸€æ­¥ï¼ˆä½¿ç”¨Qwen3-14Bï¼Œç›®æ ‡<3sï¼‰
            logger.info(f"[ReAct] æ­¥éª¤ {step_num + 1}: è§„åˆ’ä¸­...")
            import time
            plan_start = time.time()
            
            next_step = await self._planner.plan_next_step(
                intent=intent,
                screen_analysis=current_screen,
                history=history,
            )
            
            plan_time = time.time() - plan_start
            logger.info(f"[ReAct] è§„åˆ’è€—æ—¶: {plan_time:.2f}s")
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if next_step.action and next_step.action.action_type == ActionType.DONE:
                await self._tts.speak_success("ä»»åŠ¡å®Œæˆï¼")
                self._signals.status_changed.emit("å®Œæˆ")
                return
            
            # 2. æ’­æŠ¥å½“å‰æ­¥éª¤
            step_msg = next_step.friendly_instruction or next_step.description
            await self._tts.speak(f"ç¬¬{step_num + 1}æ­¥ï¼Œ{step_msg}")
            self._signals.status_changed.emit(f"æ­¥éª¤ {step_num + 1}: {step_msg[:20]}...")
            
            # 3. æ‰§è¡ŒåŠ¨ä½œï¼ˆè¿™é‡Œç­‰å¾…ç”¨æˆ·æ“ä½œæˆ–è‡ªåŠ¨æ‰§è¡Œï¼‰
            # TODO: å®ç°è‡ªåŠ¨æ‰§è¡Œï¼Œç›®å‰ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ“ä½œ
            logger.info(f"[ReAct] ç­‰å¾…ç”¨æˆ·æ‰§è¡Œ: {step_msg}")
            
            # 4. åŠ¨ä½œåå»¶è¿Ÿ0.5så†åˆ†æ
            await asyncio.sleep(0.5)
            
            # 5. è§‚å¯Ÿæ–°å±å¹•çŠ¶æ€
            new_screenshot, _ = await self._vision.capture_screen()
            if new_screenshot:
                new_state = await self._vision.analyze_screen_state(
                    new_screenshot, 
                    user_intent=intent.normalized_text
                )
                current_screen = ScreenAnalysis(
                    app_name=new_state.app_name,
                    screen_type=new_state.screen_state,
                    description=new_state.description,
                )
                current_screenshot = new_screenshot
                logger.info(f"[ReAct] æ–°å±å¹•çŠ¶æ€: {new_state.app_name} - {new_state.screen_state}")
            
            # è®°å½•å†å²
            history.append(f"{step_num + 1}. {step_msg}")
            
            # ç®€å•ç­‰å¾…è®©ç”¨æˆ·æœ‰æ—¶é—´æ“ä½œ
            await asyncio.sleep(2)
        
        # è¾¾åˆ°æœ€å¤§æ­¥éª¤
        await self._tts.speak("æ“ä½œæ­¥éª¤è¾ƒå¤šï¼Œè¯·å‘Šè¯‰æˆ‘æ˜¯å¦éœ€è¦ç»§ç»­")
        self._signals.status_changed.emit("ç­‰å¾…ç¡®è®¤")

    async def process_question(self, question: str):
        """å¤„ç†ç”¨æˆ·æé—®ï¼ˆç®€å•é—®ç­”ï¼Œä¸æ‰§è¡Œä»»åŠ¡ï¼‰"""
        self._reset_idle_timer()
        try:
            self._signals.status_changed.emit("æ€è€ƒä¸­...")
            logger.info(f"[æé—®] ç”¨æˆ·é—®é¢˜: {question}")
            
            # RAGæœç´¢ç›¸å…³çŸ¥è¯†
            logger.info("=" * 50)
            logger.info("[RAGæœç´¢] æœç´¢é—®é¢˜ç›¸å…³çŸ¥è¯†...")
            try:
                rag_result = await self._rag.retrieve(question, top_k=5)
                if rag_result.guides or rag_result.nodes:
                    logger.info(f"[RAGæœç´¢] æ‰¾åˆ° {len(rag_result.guides)} æ¡æŒ‡å—, {len(rag_result.nodes)} ä¸ªçŸ¥è¯†èŠ‚ç‚¹")
                    logger.info(f"[RAGæœç´¢] ç½®ä¿¡åº¦: {rag_result.confidence:.3f}")
                    for i, guide in enumerate(rag_result.guides):
                        logger.info(f"  [æŒ‡å—{i+1}] {guide.title}")
                        logger.info(f"      åº”ç”¨: {guide.app_name}, åŠŸèƒ½: {guide.feature_name}")
                        logger.info(f"      æ­¥éª¤: {' -> '.join(guide.steps[:3])}...")
                    for i, node in enumerate(rag_result.nodes):
                        logger.info(f"  [èŠ‚ç‚¹{i+1}] {node.name}")
                        logger.info(f"      æè¿°: {node.description[:100]}...")
                    context = rag_result.context
                    if context:
                        logger.info(f"[RAGä¸Šä¸‹æ–‡]\n{context}")
                else:
                    logger.info("[RAGæœç´¢] æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
                    context = ""
            except Exception as e:
                logger.warning(f"[RAGæœç´¢] æœç´¢å¤±è´¥: {e}")
                context = ""
            logger.info("=" * 50)
            
            # ä½¿ç”¨LLMå›ç­”é—®é¢˜
            if context:
                prompt = f"æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n\nçŸ¥è¯†ï¼š{context}\n\né—®é¢˜ï¼š{question}\n\nè¯·ç”¨ç®€æ´æ˜“æ‡‚çš„è¯­è¨€å›ç­”ï¼š"
            else:
                prompt = f"è¯·ç”¨ç®€æ´æ˜“æ‡‚çš„è¯­è¨€å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{question}"
            
            response = await self._llm.chat(prompt)
            logger.info(f"[å›ç­”] {response}")
            
            await self._tts.speak(response)
            self._signals.status_changed.emit("å›ç­”å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å›ç­”é—®é¢˜å‡ºé”™: {e}")
            await self._tts.speak("æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜")
            self._signals.status_changed.emit("å‡ºé”™")
        finally:
            self._signals.processing_done.emit()


class SimpleAssistantUI(QWidget):
    """ç®€æ´åŠ©æ‰‹ç•Œé¢"""
    
    def __init__(self):
        super().__init__()
        self._drag_pos = QPoint()
        self._is_recording = False
        self._is_processing = False
        self._current_input_type = "requirement"  # requirement æˆ– question
        self._signals = SignalBridge()
        self._agent = None
        self._loop = None
        self._agent_thread = None
        
        self._signals.status_changed.connect(self._on_status_changed)
        self._signals.recording_done.connect(self._on_recording_done)
        self._signals.processing_done.connect(self._on_processing_done)
        self._signals.reset_done.connect(self._on_reset_done)
        
        self.initUI()
        self._start_agent()
    
    def initUI(self):
        """åˆå§‹åŒ–ç•Œé¢"""
        self.setWindowFlags(Qt.FramelessWindowHint | Qt.WindowStaysOnTopHint | Qt.Tool)
        self.setAttribute(Qt.WA_TranslucentBackground)
        self.setFixedSize(550, 70)
        
        screen = QApplication.primaryScreen().geometry()
        self.move((screen.width() - 550) // 2, 20)
        
        layout = QHBoxLayout(self)
        layout.setContentsMargins(15, 10, 15, 10)
        layout.setSpacing(8)
        
        # éœ€æ±‚å½•éŸ³æŒ‰é’®ï¼ˆå¼€å§‹/åœæ­¢ï¼‰
        self._req_btn = QPushButton("ğŸ¤éœ€æ±‚")
        self._req_btn.setFixedSize(70, 50)
        self._req_btn.setCursor(Qt.PointingHandCursor)
        self._req_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFB75E, stop:1 #ED8F03);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFC988, stop:1 #FF9D00); }
        """)
        self._req_btn.clicked.connect(self._on_req_click)
        layout.addWidget(self._req_btn)
        
        # æé—®å½•éŸ³æŒ‰é’®
        self._ask_btn = QPushButton("â“æé—®")
        self._ask_btn.setFixedSize(70, 50)
        self._ask_btn.setCursor(Qt.PointingHandCursor)
        self._ask_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #667eea, stop:1 #764ba2);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #7c94f4, stop:1 #8b5fbf); }
        """)
        self._ask_btn.clicked.connect(self._on_ask_click)
        layout.addWidget(self._ask_btn)
        
        # è¾“å…¥æ¡†
        self._input = QLineEdit()
        self._input.setPlaceholderText("è¾“å…¥éœ€æ±‚æˆ–é—®é¢˜...")
        self._input.setStyleSheet("""
            QLineEdit {
                background: rgba(255,255,255,0.15); border: 1px solid rgba(255,255,255,0.3);
                border-radius: 15px; color: white; font-size: 14px; padding: 8px 12px;
            }
        """)
        self._input.returnPressed.connect(self._on_send)
        layout.addWidget(self._input)
        
        # å‘é€æŒ‰é’®
        self._send_btn = QPushButton("â¤")
        self._send_btn.setFixedSize(45, 45)
        self._send_btn.setCursor(Qt.PointingHandCursor)
        self._send_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #4ade80, stop:1 #22c55e);
                border: none; border-radius: 22px; color: white; font-size: 18px;
            }
            QPushButton:hover { background: #16a34a; }
        """)
        self._send_btn.clicked.connect(self._on_send)
        layout.addWidget(self._send_btn)
        
        # é‡æ–°å¼€å§‹æŒ‰é’®
        self._reset_btn = QPushButton("ğŸ”„")
        self._reset_btn.setFixedSize(45, 45)
        self._reset_btn.setCursor(Qt.PointingHandCursor)
        self._reset_btn.setToolTip("é‡æ–°å¼€å§‹")
        self._reset_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #f97316, stop:1 #ea580c);
                border: none; border-radius: 22px; color: white; font-size: 18px;
            }
            QPushButton:hover { background: #c2410c; }
        """)
        self._reset_btn.clicked.connect(self._on_reset_click)
        layout.addWidget(self._reset_btn)
        
        # å…³é—­æŒ‰é’®
        close_btn = QPushButton("Ã—")
        close_btn.setFixedSize(30, 30)
        close_btn.setCursor(Qt.PointingHandCursor)
        close_btn.setStyleSheet("""
            QPushButton {
                background: rgba(255,255,255,0.1); border: none; border-radius: 15px;
                color: white; font-size: 18px;
            }
            QPushButton:hover { background: #ef4444; }
        """)
        close_btn.clicked.connect(self.close)
        layout.addWidget(close_btn)
        
        # æ³¨æ„ï¼šåœ¨Windowsä¸Šé€æ˜çª—å£ä½¿ç”¨é˜´å½±æ•ˆæœå¯èƒ½å¯¼è‡´UpdateLayeredWindowIndirecté”™è¯¯
        # å¦‚éœ€é˜´å½±æ•ˆæœï¼Œå¯å–æ¶ˆä¸‹é¢æ³¨é‡Š
        # shadow = QGraphicsDropShadowEffect()
        # shadow.setBlurRadius(20)
        # shadow.setColor(QColor(0, 0, 0, 100))
        # shadow.setOffset(0, 4)
        # self.setGraphicsEffect(shadow)

    def paintEvent(self, event):
        """ç»˜åˆ¶èƒŒæ™¯"""
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        path = QPainterPath()
        path.addRoundedRect(0, 0, self.width(), self.height(), 35, 35)
        gradient = QLinearGradient(0, 0, 0, self.height())
        gradient.setColorAt(0, QColor("#164270"))
        gradient.setColorAt(1, QColor("#24548C"))
        painter.fillPath(path, QBrush(gradient))
    
    def mousePressEvent(self, event):
        if event.button() == Qt.LeftButton:
            self._drag_pos = event.globalPos() - self.frameGeometry().topLeft()
    
    def mouseMoveEvent(self, event):
        if event.buttons() == Qt.LeftButton:
            self.move(event.globalPos() - self._drag_pos)

    def _start_agent(self):
        """å¯åŠ¨Agentçº¿ç¨‹"""
        def run():
            self._loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self._loop)
            self._agent = ElderlyAgent(self._signals)
            try:
                self._loop.run_until_complete(self._agent.initialize())
                self._loop.run_forever()
            except Exception as e:
                logger.error(f"Agenté”™è¯¯: {e}")
            finally:
                if self._agent:
                    self._loop.run_until_complete(self._agent.close())
                self._loop.close()
        
        self._agent_thread = threading.Thread(target=run, daemon=True)
        self._agent_thread.start()

    def _on_req_click(self):
        """éœ€æ±‚æŒ‰é’®ç‚¹å‡» - å¼€å§‹/åœæ­¢å½•éŸ³"""
        if self._is_processing:
            return
        
        if not self._is_recording:
            # å¼€å§‹å½•éŸ³
            self._is_recording = True
            self._current_input_type = "requirement"
            self._req_btn.setText("â¹åœæ­¢")
            self._req_btn.setStyleSheet("""
                QPushButton {
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FF5F6D, stop:1 #FFC371);
                    border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
                }
            """)
            self._ask_btn.setEnabled(False)
            self._input.setPlaceholderText("æ­£åœ¨å½•éŸ³...ç‚¹å‡»åœæ­¢ç»“æŸ")
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(self._agent.start_recording(), self._loop)
        else:
            # åœæ­¢å½•éŸ³
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(
                    self._agent.stop_recording("requirement"), self._loop
                )

    def _on_ask_click(self):
        """æé—®æŒ‰é’®ç‚¹å‡» - å¼€å§‹/åœæ­¢å½•éŸ³"""
        if self._is_processing:
            return
        
        if not self._is_recording:
            # å¼€å§‹å½•éŸ³
            self._is_recording = True
            self._current_input_type = "question"
            self._ask_btn.setText("â¹åœæ­¢")
            self._ask_btn.setStyleSheet("""
                QPushButton {
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FF5F6D, stop:1 #FFC371);
                    border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
                }
            """)
            self._req_btn.setEnabled(False)
            self._input.setPlaceholderText("æ­£åœ¨å½•éŸ³...ç‚¹å‡»åœæ­¢ç»“æŸ")
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(self._agent.start_recording(), self._loop)
        else:
            # åœæ­¢å½•éŸ³
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(
                    self._agent.stop_recording("question"), self._loop
                )

    def _on_recording_done(self, text: str, input_type: str):
        """å½•éŸ³å®Œæˆ"""
        self._is_recording = False
        
        # æ¢å¤æŒ‰é’®çŠ¶æ€
        self._req_btn.setText("ğŸ¤éœ€æ±‚")
        self._req_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFB75E, stop:1 #ED8F03);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFC988, stop:1 #FF9D00); }
        """)
        self._req_btn.setEnabled(True)
        
        self._ask_btn.setText("â“æé—®")
        self._ask_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #667eea, stop:1 #764ba2);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #7c94f4, stop:1 #8b5fbf); }
        """)
        self._ask_btn.setEnabled(True)
        
        self._input.setPlaceholderText("è¾“å…¥éœ€æ±‚æˆ–é—®é¢˜...")
        
        if text:
            self._input.setText(text)
            # æ ¹æ®è¾“å…¥ç±»å‹å¤„ç†
            if input_type == "requirement":
                self._process_requirement()
            else:
                self._process_question()

    def _on_send(self):
        """å‘é€æŒ‰é’® - é»˜è®¤ä½œä¸ºéœ€æ±‚å¤„ç†"""
        self._process_requirement()

    def _process_requirement(self):
        """å¤„ç†éœ€æ±‚"""
        if self._is_processing:
            return
        text = self._input.text().strip()
        if not text:
            return
        self._input.clear()
        self._is_processing = True
        self._set_buttons_enabled(False)
        
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.process_requirement(text), self._loop)

    def _process_question(self):
        """å¤„ç†æé—®"""
        if self._is_processing:
            return
        text = self._input.text().strip()
        if not text:
            return
        self._input.clear()
        self._is_processing = True
        self._set_buttons_enabled(False)
        
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.process_question(text), self._loop)

    def _on_reset_click(self):
        """é‡æ–°å¼€å§‹æŒ‰é’®ç‚¹å‡»"""
        if self._is_recording:
            return
        self._input.clear()
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.reset_flow(), self._loop)

    def _on_reset_done(self):
        """é‡ç½®å®Œæˆ"""
        self._is_processing = False
        self._set_buttons_enabled(True)
        self._input.setPlaceholderText("è¯·è¯´å‡ºæ‚¨çš„éœ€æ±‚...")

    def _set_buttons_enabled(self, enabled: bool):
        """è®¾ç½®æŒ‰é’®å¯ç”¨çŠ¶æ€"""
        self._req_btn.setEnabled(enabled)
        self._ask_btn.setEnabled(enabled)
        self._send_btn.setEnabled(enabled)
        self._input.setEnabled(enabled)

    def _on_status_changed(self, status: str):
        """çŠ¶æ€å˜åŒ–"""
        self._input.setPlaceholderText(status)
    
    def _on_processing_done(self):
        """å¤„ç†å®Œæˆ"""
        self._is_processing = False
        self._set_buttons_enabled(True)
        self._input.setPlaceholderText("è¾“å…¥éœ€æ±‚æˆ–é—®é¢˜...")
    
    def closeEvent(self, event):
        """å…³é—­"""
        if self._loop:
            self._loop.call_soon_threadsafe(self._loop.stop)
        event.accept()


def main():
    logger.remove()
    logger.add(sys.stderr, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>")
    
    app = QApplication(sys.argv)
    app.setFont(QFont("Microsoft YaHei", 12))
    
    window = SimpleAssistantUI()
    window.show()
    
    sys.exit(app.exec_())


if __name__ == '__main__':
    main()
