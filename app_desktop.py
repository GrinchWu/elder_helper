"""
æ™ºèƒ½åŠ©æ‰‹æ¡Œé¢åº”ç”¨ - ç®€æ´ç‰ˆ
é›†æˆè¯­éŸ³è¾“å…¥/è¾“å‡ºã€ä»»åŠ¡æ‰§è¡ŒåŠŸèƒ½
æ”¯æŒï¼šéœ€æ±‚å½•éŸ³ã€æé—®å½•éŸ³ã€é‡æ–°å¼€å§‹æµç¨‹
"""
import sys
import asyncio
import threading
from PyQt5.QtWidgets import (QApplication, QWidget, QHBoxLayout, QVBoxLayout,
                             QLabel, QPushButton, QLineEdit, QGraphicsDropShadowEffect)
from PyQt5.QtCore import Qt, QPoint, pyqtSignal, QObject
from PyQt5.QtGui import QFont, QColor, QPainter, QPainterPath, QBrush, QLinearGradient

from src.config import config
from src.models.intent import Intent
from src.models.task import Task, TaskStatus, TaskPlan
from src.models.session import UserProfile
from src.models.knowledge import KnowledgeGraph
from src.services.llm_service import LLMService
from src.services.vision_service import VisionService, VLConfig, ScreenAnalysis
from src.services.planner_service import PlannerService
from src.services.safety_service import SafetyService
from src.services.executor_service import ExecutorService
from src.services.embedding_service import EmbeddingService
from src.services.tts_service import TTSService
from src.services.asr_service import ASRService, ASRConfig, AudioCapture
from src.knowledge.rag_service import RAGService
from src.knowledge.video_extractor import VideoKnowledgeExtractor
from src.models.action import Action, ActionType
from loguru import logger


class SignalBridge(QObject):
    """Qtä¿¡å·æ¡¥æ¥å™¨ï¼Œç”¨äºçº¿ç¨‹é—´é€šä¿¡"""
    status_changed = pyqtSignal(str)
    message_received = pyqtSignal(str)
    recording_done = pyqtSignal(str, str)  # (text, input_type)
    processing_done = pyqtSignal()
    reset_done = pyqtSignal()


class ElderlyAgent:
    """è€å¹´äººåŠ©æ‰‹Agent"""
    
    def __init__(self, signals: SignalBridge):
        self._signals = signals
        self._llm = None
        self._vision = None
        self._planner = None
        self._safety = None
        self._executor = None
        self._embedding = None
        self._rag = None
        self._knowledge_graph = None
        self._video_extractor = None
        self._tts = None
        self._asr = None
        self._audio_capture = None
        self._user_profile = None
        self._current_plan = None
        self._current_intent = None
        self._idle_timeout = 30
        self._last_action_time = None
        self._idle_check_task = None
        self._is_recording = False  # å½•éŸ³çŠ¶æ€

    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
        self._signals.status_changed.emit("åˆå§‹åŒ–è¯­éŸ³æœåŠ¡...")
        self._tts = TTSService()
        await self._tts.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«...")
        asr_config = ASRConfig(
            project_id=config.asr.project_id,
            easyllm_id=config.asr.easyllm_id,
            api_key=config.asr.api_key,
        )
        self._asr = ASRService(asr_config)
        await self._asr.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–æ„å›¾ç†è§£...")
        self._llm = LLMService()
        await self._llm.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è§†è§‰æœåŠ¡...")
        vl_config = VLConfig(
            api_key=config.api.api_key,
            model_light=config.api.vl_model_light,
            model_heavy=config.api.vl_model_heavy,
        )
        self._vision = VisionService(vl_config)
        await self._vision.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è§„åˆ’æœåŠ¡...")
        self._planner = PlannerService()
        await self._planner.initialize()
        
        self._safety = SafetyService()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–çŸ¥è¯†æœåŠ¡...")
        self._embedding = EmbeddingService()
        await self._embedding.initialize()
        
        self._knowledge_graph = KnowledgeGraph()
        self._rag = RAGService()
        await self._rag.initialize(
            embedding_service=self._embedding,
            knowledge_graph=self._knowledge_graph,
        )
        self._planner.set_rag_service(self._rag)
        
        # æ„å»ºçŸ¥è¯†åº“ï¼ˆä»Bç«™æœç´¢æˆ–ä½¿ç”¨é¢„ç½®æ•°æ®ï¼‰
        self._signals.status_changed.emit("æ„å»ºçŸ¥è¯†åº“...")
        self._video_extractor = VideoKnowledgeExtractor()
        await self._video_extractor.initialize()
        
        try:
            # ä½¿ç”¨å¸¦å›é€€çš„æ„å»ºæ–¹æ³•ï¼ˆå¦‚æœBç«™æœç´¢å¤±è´¥åˆ™ä½¿ç”¨é¢„ç½®æ•°æ®ï¼‰
            kb_stats = await self._video_extractor.build_knowledge_base_with_fallback(self._rag)
            logger.info(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆ: {kb_stats}")
        except Exception as e:
            logger.warning(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼Œä½¿ç”¨é¢„ç½®æ•°æ®: {e}")
            await self._video_extractor._load_preset_knowledge(self._rag)
        
        self._signals.status_changed.emit("åˆå§‹åŒ–æ‰§è¡ŒæœåŠ¡...")
        self._executor = ExecutorService()
        self._executor.set_vision_service(self._vision)
        self._executor.set_planner_service(self._planner)
        await self._executor.initialize()
        
        self._user_profile = UserProfile(
            name="ç”¨æˆ·",
            family_mapping={"è€äºŒ": "å¼ å°æ˜", "é—ºå¥³": "å¼ å°çº¢"},
            frequent_contacts=["å¼ å°æ˜", "å¼ å°çº¢"],
        )
        
        self._signals.status_changed.emit("å‡†å¤‡å°±ç»ª")
        await self._tts.speak_welcome()
        
        self._last_action_time = asyncio.get_event_loop().time()
        self._idle_check_task = asyncio.create_task(self._check_idle())

    async def _check_idle(self):
        """æ£€æµ‹ç”¨æˆ·æ˜¯å¦é•¿æ—¶é—´æ— åŠ¨ä½œ"""
        while True:
            await asyncio.sleep(5)
            if self._last_action_time:
                elapsed = asyncio.get_event_loop().time() - self._last_action_time
                if elapsed >= self._idle_timeout:
                    await self._tts.speak("æ‚¨å¥½ï¼Œéœ€è¦æˆ‘å¸®æ‚¨åšä»€ä¹ˆå—ï¼Ÿ")
                    self._last_action_time = asyncio.get_event_loop().time()
    
    def _reset_idle_timer(self):
        """é‡ç½®ç©ºé—²è®¡æ—¶å™¨"""
        self._last_action_time = asyncio.get_event_loop().time()

    async def close(self):
        """å…³é—­æœåŠ¡"""
        if self._idle_check_task:
            self._idle_check_task.cancel()
        for svc in [self._asr, self._tts, self._llm, self._vision, 
                    self._planner, self._executor, self._embedding, self._video_extractor]:
            if svc:
                await svc.close()

    async def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if self._is_recording:
            return
        self._is_recording = True
        self._reset_idle_timer()
        await self._tts.speak("å¼€å§‹å½•éŸ³ï¼Œè¯·è¯´è¯")
        self._audio_capture = AudioCapture(sample_rate=config.asr.sample_rate)
        self._audio_capture.start()
        logger.info("å½•éŸ³å·²å¼€å§‹")

    async def stop_recording(self, input_type: str = "requirement"):
        """åœæ­¢å½•éŸ³å¹¶è¯†åˆ«"""
        if not self._is_recording:
            self._signals.recording_done.emit("", input_type)
            return
        
        self._is_recording = False
        try:
            if self._audio_capture:
                audio_data = self._audio_capture.get_all_audio()
                self._audio_capture.stop()
                self._audio_capture = None
                
                if audio_data:
                    self._signals.status_changed.emit("è¯†åˆ«ä¸­...")
                    logger.info(f"éŸ³é¢‘æ•°æ®å¤§å°: {len(audio_data)} bytes")
                    result = await self._asr.recognize_audio(audio_data)
                    text = result.text.strip() if result.text else ""
                    if text:
                        logger.info(f"è¯†åˆ«ç»“æœ: {text}")
                        await self._tts.speak(f"æ‚¨è¯´çš„æ˜¯ï¼š{text}")
                    self._signals.recording_done.emit(text, input_type)
                else:
                    self._signals.recording_done.emit("", input_type)
        except Exception as e:
            logger.error(f"åœæ­¢å½•éŸ³å¤±è´¥: {e}")
            self._signals.recording_done.emit("", input_type)

    async def reset_flow(self):
        """é‡æ–°å¼€å§‹æµç¨‹"""
        self._current_plan = None
        self._current_intent = None
        self._reset_idle_timer()
        await self._tts.speak("å¥½çš„ï¼Œæˆ‘ä»¬é‡æ–°å¼€å§‹ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©")
        self._signals.reset_done.emit()
        logger.info("æµç¨‹å·²é‡ç½®")

    async def process_requirement(self, user_input: str):
        """å¤„ç†ç”¨æˆ·éœ€æ±‚ï¼ˆä¸»æµç¨‹ï¼‰- ä¼˜åŒ–ç‰ˆï¼šå¹¶è¡ŒåŒ– + æ··åˆè§„åˆ’æ¨¡å¼"""
        self._reset_idle_timer()
        try:
            self._signals.status_changed.emit("å®‰å…¨æ£€æŸ¥...")
            
            safety_result = self._safety.check_text_safety(user_input)
            if not safety_result.is_safe and safety_result.blocked_reason:
                await self._tts.speak(f"å®‰å…¨è­¦å‘Šï¼š{safety_result.blocked_reason}")
                self._signals.processing_done.emit()
                return
            
            # ========== å¹¶è¡Œæ‰§è¡Œï¼šæ„å›¾ç†è§£ + å±å¹•æˆªå›¾ + RAGæœç´¢ ==========
            self._signals.status_changed.emit("åˆ†æä¸­...")
            logger.info("=" * 50)
            logger.info("[å¹¶è¡Œå¤„ç†] å¼€å§‹å¹¶è¡Œæ‰§è¡Œï¼šæ„å›¾ç†è§£ + å±å¹•æˆªå›¾ + RAGæœç´¢")
            
            import time
            start_time = time.time()
            
            # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            intent_task = asyncio.create_task(
                self._llm.understand_intent(user_input, self._user_profile)
            )
            screenshot_task = asyncio.create_task(
                self._vision.capture_screen()
            )
            rag_task = asyncio.create_task(
                self._rag.retrieve(user_input, top_k=3)
            )
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            intent, (screenshot, original_size), rag_result = await asyncio.gather(
                intent_task, screenshot_task, rag_task,
                return_exceptions=True
            )
            
            parallel_time = time.time() - start_time
            logger.info(f"[å¹¶è¡Œå¤„ç†] å®Œæˆï¼Œè€—æ—¶: {parallel_time:.2f}s")
            
            # å¤„ç†å¯èƒ½çš„å¼‚å¸¸
            if isinstance(intent, Exception):
                logger.error(f"æ„å›¾ç†è§£å¤±è´¥: {intent}")
                await self._tts.speak("æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„æ€")
                self._signals.processing_done.emit()
                return
            
            if isinstance(screenshot, Exception) or not screenshot:
                logger.error(f"æˆªå±å¤±è´¥: {screenshot}")
                await self._tts.speak("æˆªå±å¤±è´¥")
                self._signals.processing_done.emit()
                return
            
            self._current_intent = intent
            logger.info(f"[æ„å›¾ç†è§£] åŸå§‹è¾“å…¥: {user_input}")
            logger.info(f"[æ„å›¾ç†è§£] è§„èŒƒåŒ–æ–‡æœ¬: {intent.normalized_text}")
            logger.info(f"[æ„å›¾ç†è§£] ç½®ä¿¡åº¦: {intent.confidence}")
            
            if intent.confidence.is_low:
                await self._tts.speak("æˆ‘ä¸å¤ªç¡®å®šæ‚¨æƒ³åšä»€ä¹ˆï¼Œèƒ½å†è¯´è¯¦ç»†ä¸€ç‚¹å—ï¼Ÿ")
                self._signals.processing_done.emit()
                return
            
            # RAGç»“æœæ—¥å¿—
            if not isinstance(rag_result, Exception) and (rag_result.guides or rag_result.nodes):
                logger.info(f"[RAGæœç´¢] æ‰¾åˆ° {len(rag_result.guides)} æ¡æŒ‡å—, {len(rag_result.nodes)} ä¸ªçŸ¥è¯†èŠ‚ç‚¹")
            else:
                logger.info("[RAGæœç´¢] æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
            
            # ========== å±å¹•åˆ†æï¼ˆéœ€è¦intentç»“æœï¼‰==========
            self._signals.status_changed.emit("åˆ†æå±å¹•...")
            screen_state = await self._vision.analyze_screen_state(
                screenshot, user_intent=intent.normalized_text or user_input
            )
            logger.info(f"[å±å¹•åˆ†æ] åº”ç”¨: {screen_state.app_name}")
            logger.info(f"[å±å¹•åˆ†æ] çŠ¶æ€: {screen_state.screen_state}")
            logger.info("=" * 50)
            
            screen_analysis = ScreenAnalysis(
                app_name=screen_state.app_name,
                screen_type=screen_state.screen_state,
                description=screen_state.description,
                suggested_actions=[screen_state.suggested_action] if screen_state.suggested_action else [],
                warnings=screen_state.warnings,
            )
            
            # ========== å®Œæ•´è§„åˆ’æ¨¡å¼ï¼šä¸€æ¬¡æ€§ç”Ÿæˆè®¡åˆ’ + æ‰§è¡Œæ—¶éªŒè¯ ==========
            self._signals.status_changed.emit("è§„åˆ’ä¸­...")
            await self._tts.speak("å¥½çš„ï¼Œæˆ‘æ¥å¸®æ‚¨æ“ä½œ")
            
            # ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´è®¡åˆ’
            await self._plan_and_execute(intent, screen_analysis, screenshot)
            
        except Exception as e:
            logger.error(f"å¤„ç†å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            await self._tts.speak_error(str(e))
            self._signals.status_changed.emit("å‡ºé”™")
        finally:
            self._reset_idle_timer()
            self._signals.processing_done.emit()
    
    async def _plan_and_execute(self, intent: Intent, screen_analysis: ScreenAnalysis, screenshot: bytes):
        """å®Œæ•´è§„åˆ’ + é€æ­¥æ‰§è¡ŒéªŒè¯æ¨¡å¼
        
        æµç¨‹ï¼š
        1. ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´è®¡åˆ’ï¼ˆä½¿ç”¨å¤§æ¨¡å‹ï¼‰
        2. é€æ­¥æ‰§è¡Œï¼Œæ¯æ­¥æ‰§è¡Œåè§‚å¯Ÿå±å¹•
        3. éªŒè¯æ‰§è¡Œç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
        4. å¦‚æœåç¦»é¢„æœŸï¼Œè§¦å‘é‡è§„åˆ’
        """
        import time
        max_replan_attempts = 3  # æœ€å¤§é‡è§„åˆ’æ¬¡æ•°
        replan_count = 0
        current_screen = screen_analysis
        current_screenshot = screenshot
        
        while replan_count <= max_replan_attempts:
            # ========== 1. ç”Ÿæˆå®Œæ•´è®¡åˆ’ ==========
            logger.info(f"[è§„åˆ’] ç”Ÿæˆå®Œæ•´è®¡åˆ’ (ç¬¬{replan_count + 1}æ¬¡)...")
            self._signals.status_changed.emit("è§„åˆ’ä¸­...")
            
            plan_start = time.time()
            plan = await self._planner.create_plan(
                intent=intent,
                screen_analysis=current_screen,
            )
            plan_time = time.time() - plan_start
            logger.info(f"[è§„åˆ’] è®¡åˆ’ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {plan_time:.2f}sï¼Œå…± {len(plan.steps)} æ­¥")
            
            # æ‰“å°è®¡åˆ’æ­¥éª¤
            for i, step in enumerate(plan.steps):
                logger.info(f"  æ­¥éª¤ {i+1}: {step.description}")
            
            if not plan.steps:
                await self._tts.speak("æŠ±æ­‰ï¼Œæˆ‘ä¸çŸ¥é“è¯¥æ€ä¹ˆå¸®æ‚¨å®Œæˆè¿™ä¸ªæ“ä½œ")
                self._signals.status_changed.emit("è§„åˆ’å¤±è´¥")
                return
            
            # æ£€æŸ¥ç¬¬ä¸€æ­¥æ˜¯å¦å°±æ˜¯å®Œæˆ
            if plan.steps[0].action and plan.steps[0].action.action_type == ActionType.DONE:
                await self._tts.speak_success("ä»»åŠ¡å·²ç»å®Œæˆäº†ï¼")
                self._signals.status_changed.emit("å®Œæˆ")
                return
            
            # æ’­æŠ¥è®¡åˆ’æ¦‚è¦
            total_steps = len([s for s in plan.steps if s.action and s.action.action_type != ActionType.DONE])
            if total_steps > 1:
                await self._tts.speak(f"éœ€è¦{total_steps}ä¸ªæ­¥éª¤")
            
            # ========== 2. é€æ­¥æ‰§è¡Œè®¡åˆ’ ==========
            self._signals.status_changed.emit("æ‰§è¡Œä¸­...")
            execution_success = True
            
            for step_idx, step in enumerate(plan.steps):
                self._reset_idle_timer()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæˆæ­¥éª¤
                if step.action and step.action.action_type == ActionType.DONE:
                    await self._tts.speak_success("ä»»åŠ¡å®Œæˆï¼")
                    self._signals.status_changed.emit("å®Œæˆ")
                    return
                
                # æ’­æŠ¥å½“å‰æ­¥éª¤
                step_msg = step.friendly_instruction
                if not step_msg or len(step_msg) > 40:
                    step_msg = self._format_action_message(step.action)
                
                logger.info(f"[æ‰§è¡Œ] æ­¥éª¤ {step_idx + 1}/{len(plan.steps)}: {step_msg}")
                self._signals.status_changed.emit(f"æ­¥éª¤ {step_idx + 1}: {step_msg[:20]}...")
                await self._tts.speak(step_msg)
                
                # ç­‰å¾…ç”¨æˆ·æ“ä½œ
                await asyncio.sleep(2.5)
                
                # ========== 3. è§‚å¯Ÿæ‰§è¡Œç»“æœ ==========
                new_screenshot, _ = await self._vision.capture_screen()
                if new_screenshot:
                    new_state = await self._vision.analyze_screen_state(
                        new_screenshot,
                        user_intent=intent.normalized_text
                    )
                    new_screen = ScreenAnalysis(
                        app_name=new_state.app_name,
                        screen_type=new_state.screen_state,
                        description=new_state.description,
                    )
                    logger.info(f"[è§‚å¯Ÿ] å½“å‰å±å¹•: {new_state.app_name} - {new_state.screen_state}")
                    
                    # ========== 4. éªŒè¯æ‰§è¡Œç»“æœ ==========
                    # æ£€æŸ¥æ˜¯å¦å·²ç»è¾¾åˆ°ç›®æ ‡çŠ¶æ€
                    if self._check_goal_reached(intent, new_screen):
                        await self._tts.speak_success("ä»»åŠ¡å®Œæˆï¼")
                        self._signals.status_changed.emit("å®Œæˆ")
                        return
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è§„åˆ’ï¼ˆå±å¹•çŠ¶æ€ä¸é¢„æœŸä¸ç¬¦ï¼‰
                    expected_result = step.expected_result or ""
                    if expected_result and not self._verify_step_result(expected_result, new_screen):
                        logger.warning(f"[éªŒè¯] æ­¥éª¤ç»“æœä¸é¢„æœŸä¸ç¬¦ï¼Œé¢„æœŸ: {expected_result}")
                        logger.warning(f"[éªŒè¯] å®é™…å±å¹•: {new_state.description[:100]}")
                        
                        # å¦‚æœè¿˜æœ‰é‡è§„åˆ’æœºä¼šï¼Œè§¦å‘é‡è§„åˆ’
                        if replan_count < max_replan_attempts:
                            await self._tts.speak("æ“ä½œç»“æœå’Œé¢„æœŸä¸å¤ªä¸€æ ·ï¼Œè®©æˆ‘é‡æ–°è§„åˆ’")
                            current_screen = new_screen
                            current_screenshot = new_screenshot
                            execution_success = False
                            break
                    
                    # æ›´æ–°å½“å‰å±å¹•çŠ¶æ€
                    current_screen = new_screen
                    current_screenshot = new_screenshot
            
            # å¦‚æœæ‰§è¡ŒæˆåŠŸå®Œæˆæ‰€æœ‰æ­¥éª¤
            if execution_success:
                # æœ€ç»ˆæ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                if self._check_goal_reached(intent, current_screen):
                    await self._tts.speak_success("ä»»åŠ¡å®Œæˆï¼")
                    self._signals.status_changed.emit("å®Œæˆ")
                else:
                    await self._tts.speak("æ“ä½œæ­¥éª¤å·²å®Œæˆï¼Œè¯·æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‚¨çš„ç›®æ ‡")
                    self._signals.status_changed.emit("å·²å®Œæˆæ­¥éª¤")
                return
            
            # é‡è§„åˆ’
            replan_count += 1
            logger.info(f"[é‡è§„åˆ’] è§¦å‘é‡è§„åˆ’ï¼Œç¬¬ {replan_count} æ¬¡")
        
        # è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•°
        await self._tts.speak("å¤šæ¬¡å°è¯•åä»æ— æ³•å®Œæˆï¼Œè¯·å‘Šè¯‰æˆ‘å…·ä½“é‡åˆ°äº†ä»€ä¹ˆé—®é¢˜")
        self._signals.status_changed.emit("éœ€è¦å¸®åŠ©")
    
    def _check_goal_reached(self, intent: Intent, screen: ScreenAnalysis) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ç›®æ ‡çŠ¶æ€"""
        # å¦‚æœæœ‰ç›®æ ‡åº”ç”¨ï¼Œæ£€æŸ¥æ˜¯å¦å·²æ‰“å¼€
        if intent.target_app:
            target_app = intent.target_app.lower()
            current_app = screen.app_name.lower()
            
            # æµè§ˆå™¨ç±»åº”ç”¨ç‰¹æ®Šå¤„ç†
            browser_keywords = ["æµè§ˆå™¨", "edge", "chrome", "firefox", "360", "browser"]
            if any(kw in target_app for kw in browser_keywords):
                if any(kw in current_app for kw in browser_keywords):
                    return True
            elif target_app in current_app or current_app in target_app:
                return True
        
        # å¦‚æœæœ‰ç›®æ ‡çŠ¶æ€æè¿°ï¼Œæ£€æŸ¥å…³é”®è¯åŒ¹é…
        if intent.target_state:
            target_keywords = [kw for kw in intent.target_state.lower().split() if len(kw) > 1]
            current_state = f"{screen.app_name} {screen.screen_type} {screen.description}".lower()
            
            if target_keywords:
                match_count = sum(1 for kw in target_keywords if kw in current_state)
                if match_count >= len(target_keywords) * 0.5:
                    return True
        
        return False
    
    def _verify_step_result(self, expected: str, screen: ScreenAnalysis) -> bool:
        """éªŒè¯æ­¥éª¤æ‰§è¡Œç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ"""
        if not expected:
            return True
        
        expected_lower = expected.lower()
        current_state = f"{screen.app_name} {screen.screen_type} {screen.description}".lower()
        
        # æå–é¢„æœŸç»“æœçš„å…³é”®è¯
        keywords = [kw for kw in expected_lower.split() if len(kw) > 1]
        if not keywords:
            return True
        
        # æ£€æŸ¥å…³é”®è¯åŒ¹é…ç‡
        match_count = sum(1 for kw in keywords if kw in current_state)
        return match_count >= len(keywords) * 0.3  # 30%åŒ¹é…å³è®¤ä¸ºç¬¦åˆé¢„æœŸ

    async def _react_execution_loop(self, intent: Intent, screen_analysis: ScreenAnalysis, screenshot: bytes):
        """ReActå¾ªç¯æ‰§è¡Œæ¨¡å¼ - è§‚å¯Ÿ->è§„åˆ’->æ‰§è¡Œ->è§‚å¯Ÿ..."""
        max_steps = 10
        history = []
        current_screen = screen_analysis
        current_screenshot = screenshot
        
        for step_num in range(max_steps):
            self._reset_idle_timer()
            
            # 1. å¿«é€Ÿè§„åˆ’ä¸‹ä¸€æ­¥ï¼ˆä½¿ç”¨Qwen3-14Bï¼Œç›®æ ‡<3sï¼‰
            logger.info(f"[ReAct] æ­¥éª¤ {step_num + 1}: è§„åˆ’ä¸­...")
            import time
            plan_start = time.time()
            
            next_step = await self._planner.plan_next_step(
                intent=intent,
                screen_analysis=current_screen,
                history=history,
            )
            
            plan_time = time.time() - plan_start
            logger.info(f"[ReAct] è§„åˆ’è€—æ—¶: {plan_time:.2f}s")
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if next_step.action and next_step.action.action_type == ActionType.DONE:
                await self._tts.speak_success("ä»»åŠ¡å®Œæˆï¼")
                self._signals.status_changed.emit("å®Œæˆ")
                return
            
            # 2. æ’­æŠ¥å½“å‰æ­¥éª¤ - åªè¾“å‡ºåŠ¨ä½œï¼Œä¸è¾“å‡ºæ€è€ƒè¿‡ç¨‹
            # ä¼˜å…ˆä½¿ç”¨ friendly_instructionï¼ˆå·²ç»æ˜¯ç®€æ´çš„åŠ¨ä½œæè¿°ï¼‰
            step_msg = next_step.friendly_instruction
            
            # å¦‚æœ friendly_instruction ä¸ºç©ºæˆ–å¤ªé•¿ï¼Œç›´æ¥ä» action ç”Ÿæˆ
            if not step_msg or len(step_msg) > 30:
                step_msg = self._format_action_message(next_step.action)
            
            await self._tts.speak(step_msg)
            self._signals.status_changed.emit(f"æ­¥éª¤ {step_num + 1}: {step_msg[:20]}...")
            logger.info(f"[ReAct] æ‰§è¡Œ: {step_msg}")
            
            # 3. åŠ¨ä½œåå»¶è¿Ÿ0.5så†åˆ†æ
            await asyncio.sleep(0.5)
            
            # 4. è§‚å¯Ÿæ–°å±å¹•çŠ¶æ€
            new_screenshot, _ = await self._vision.capture_screen()
            if new_screenshot:
                new_state = await self._vision.analyze_screen_state(
                    new_screenshot, 
                    user_intent=intent.normalized_text
                )
                current_screen = ScreenAnalysis(
                    app_name=new_state.app_name,
                    screen_type=new_state.screen_state,
                    description=new_state.description,
                )
                current_screenshot = new_screenshot
                logger.info(f"[ReAct] æ–°å±å¹•çŠ¶æ€: {new_state.app_name} - {new_state.screen_state}")
            
            # è®°å½•å†å²ï¼ˆç®€çŸ­æè¿°ï¼‰
            history.append(f"{step_num + 1}. {step_msg}")
            
            # ç®€å•ç­‰å¾…è®©ç”¨æˆ·æœ‰æ—¶é—´æ“ä½œ
            await asyncio.sleep(2)
        
        # è¾¾åˆ°æœ€å¤§æ­¥éª¤
        await self._tts.speak("æ“ä½œæ­¥éª¤è¾ƒå¤šï¼Œè¯·å‘Šè¯‰æˆ‘æ˜¯å¦éœ€è¦ç»§ç»­")
        self._signals.status_changed.emit("ç­‰å¾…ç¡®è®¤")

    def _format_action_message(self, action: Action) -> str:
        """æ ¼å¼åŒ–åŠ¨ä½œä¸ºç®€æ´çš„è¯­éŸ³è¾“å‡ºï¼ˆåªæè¿°åŠ¨ä½œæœ¬èº«ï¼‰"""
        if not action:
            return "è¯·ç¨ç­‰"
        
        action_type = action.action_type
        target = action.element_description or ""
        text = action.text or ""
        key = action.key or ""
        hotkey = action.hotkey or ""
        
        # é™åˆ¶ç›®æ ‡æè¿°é•¿åº¦
        if len(target) > 15:
            target = target[:15]
        
        if action_type == ActionType.CLICK:
            return f"è¯·ç‚¹å‡»{target}" if target else "è¯·ç‚¹å‡»"
        elif action_type == ActionType.DOUBLE_CLICK:
            return f"è¯·åŒå‡»{target}" if target else "è¯·åŒå‡»"
        elif action_type == ActionType.RIGHT_CLICK:
            return f"è¯·å³é”®ç‚¹å‡»{target}" if target else "è¯·å³é”®ç‚¹å‡»"
        elif action_type == ActionType.TYPE:
            return f"è¯·è¾“å…¥{text}" if text else "è¯·è¾“å…¥"
        elif action_type == ActionType.KEY_PRESS:
            return f"è¯·æŒ‰{key}é”®" if key else "è¯·æŒ‰é”®"
        elif action_type == ActionType.HOTKEY:
            return f"è¯·æŒ‰{hotkey}" if hotkey else "è¯·æŒ‰ç»„åˆé”®"
        elif action_type == ActionType.SCROLL:
            direction = action.scroll_direction or "down"
            return "è¯·å‘ä¸Šæ»šåŠ¨" if direction == "up" else "è¯·å‘ä¸‹æ»šåŠ¨"
        elif action_type == ActionType.DRAG:
            return f"è¯·æ‹–åŠ¨{target}" if target else "è¯·æ‹–åŠ¨"
        elif action_type == ActionType.WAIT:
            return "è¯·ç¨ç­‰"
        elif action_type == ActionType.WAIT_ELEMENT:
            return f"è¯·ç­‰å¾…{target}å‡ºç°" if target else "è¯·ç­‰å¾…"
        elif action_type == ActionType.DONE:
            return "å®Œæˆ"
        else:
            return "è¯·æ“ä½œ"

    async def process_question(self, question: str):
        """å¤„ç†ç”¨æˆ·æé—®ï¼ˆç®€å•é—®ç­”ï¼Œä¸æ‰§è¡Œä»»åŠ¡ï¼‰"""
        self._reset_idle_timer()
        try:
            self._signals.status_changed.emit("æ€è€ƒä¸­...")
            logger.info(f"[æé—®] ç”¨æˆ·é—®é¢˜: {question}")
            
            # RAGæœç´¢ç›¸å…³çŸ¥è¯†
            logger.info("=" * 50)
            logger.info("[RAGæœç´¢] æœç´¢é—®é¢˜ç›¸å…³çŸ¥è¯†...")
            try:
                rag_result = await self._rag.retrieve(question, top_k=5)
                if rag_result.guides or rag_result.nodes:
                    logger.info(f"[RAGæœç´¢] æ‰¾åˆ° {len(rag_result.guides)} æ¡æŒ‡å—, {len(rag_result.nodes)} ä¸ªçŸ¥è¯†èŠ‚ç‚¹")
                    logger.info(f"[RAGæœç´¢] ç½®ä¿¡åº¦: {rag_result.confidence:.3f}")
                    for i, guide in enumerate(rag_result.guides):
                        logger.info(f"  [æŒ‡å—{i+1}] {guide.title}")
                        logger.info(f"      åº”ç”¨: {guide.app_name}, åŠŸèƒ½: {guide.feature_name}")
                        logger.info(f"      æ­¥éª¤: {' -> '.join(guide.steps[:3])}...")
                    for i, node in enumerate(rag_result.nodes):
                        logger.info(f"  [èŠ‚ç‚¹{i+1}] {node.name}")
                        logger.info(f"      æè¿°: {node.description[:100]}...")
                    context = rag_result.context
                    if context:
                        logger.info(f"[RAGä¸Šä¸‹æ–‡]\n{context}")
                else:
                    logger.info("[RAGæœç´¢] æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
                    context = ""
            except Exception as e:
                logger.warning(f"[RAGæœç´¢] æœç´¢å¤±è´¥: {e}")
                context = ""
            logger.info("=" * 50)
            
            # ä½¿ç”¨LLMå›ç­”é—®é¢˜
            if context:
                prompt = f"æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n\nçŸ¥è¯†ï¼š{context}\n\né—®é¢˜ï¼š{question}\n\nè¯·ç”¨ç®€æ´æ˜“æ‡‚çš„è¯­è¨€å›ç­”ï¼š"
            else:
                prompt = f"è¯·ç”¨ç®€æ´æ˜“æ‡‚çš„è¯­è¨€å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{question}"
            
            response = await self._llm.chat(prompt)
            logger.info(f"[å›ç­”] {response}")
            
            await self._tts.speak(response)
            self._signals.status_changed.emit("å›ç­”å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å›ç­”é—®é¢˜å‡ºé”™: {e}")
            await self._tts.speak("æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜")
            self._signals.status_changed.emit("å‡ºé”™")
        finally:
            self._signals.processing_done.emit()


class SimpleAssistantUI(QWidget):
    """ç®€æ´åŠ©æ‰‹ç•Œé¢"""
    
    def __init__(self):
        super().__init__()
        self._drag_pos = QPoint()
        self._is_recording = False
        self._is_processing = False
        self._current_input_type = "requirement"  # requirement æˆ– question
        self._signals = SignalBridge()
        self._agent = None
        self._loop = None
        self._agent_thread = None
        
        self._signals.status_changed.connect(self._on_status_changed)
        self._signals.recording_done.connect(self._on_recording_done)
        self._signals.processing_done.connect(self._on_processing_done)
        self._signals.reset_done.connect(self._on_reset_done)
        
        self.initUI()
        self._start_agent()
    
    def initUI(self):
        """åˆå§‹åŒ–ç•Œé¢"""
        self.setWindowFlags(Qt.FramelessWindowHint | Qt.WindowStaysOnTopHint | Qt.Tool)
        self.setAttribute(Qt.WA_TranslucentBackground)
        self.setFixedSize(550, 70)
        
        screen = QApplication.primaryScreen().geometry()
        self.move((screen.width() - 550) // 2, 20)
        
        layout = QHBoxLayout(self)
        layout.setContentsMargins(15, 10, 15, 10)
        layout.setSpacing(8)
        
        # éœ€æ±‚å½•éŸ³æŒ‰é’®ï¼ˆå¼€å§‹/åœæ­¢ï¼‰
        self._req_btn = QPushButton("ğŸ¤éœ€æ±‚")
        self._req_btn.setFixedSize(70, 50)
        self._req_btn.setCursor(Qt.PointingHandCursor)
        self._req_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFB75E, stop:1 #ED8F03);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFC988, stop:1 #FF9D00); }
        """)
        self._req_btn.clicked.connect(self._on_req_click)
        layout.addWidget(self._req_btn)
        
        # æé—®å½•éŸ³æŒ‰é’®
        self._ask_btn = QPushButton("â“æé—®")
        self._ask_btn.setFixedSize(70, 50)
        self._ask_btn.setCursor(Qt.PointingHandCursor)
        self._ask_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #667eea, stop:1 #764ba2);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #7c94f4, stop:1 #8b5fbf); }
        """)
        self._ask_btn.clicked.connect(self._on_ask_click)
        layout.addWidget(self._ask_btn)
        
        # è¾“å…¥æ¡†
        self._input = QLineEdit()
        self._input.setPlaceholderText("è¾“å…¥éœ€æ±‚æˆ–é—®é¢˜...")
        self._input.setStyleSheet("""
            QLineEdit {
                background: rgba(255,255,255,0.15); border: 1px solid rgba(255,255,255,0.3);
                border-radius: 15px; color: white; font-size: 14px; padding: 8px 12px;
            }
        """)
        self._input.returnPressed.connect(self._on_send)
        layout.addWidget(self._input)
        
        # å‘é€æŒ‰é’®
        self._send_btn = QPushButton("â¤")
        self._send_btn.setFixedSize(45, 45)
        self._send_btn.setCursor(Qt.PointingHandCursor)
        self._send_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #4ade80, stop:1 #22c55e);
                border: none; border-radius: 22px; color: white; font-size: 18px;
            }
            QPushButton:hover { background: #16a34a; }
        """)
        self._send_btn.clicked.connect(self._on_send)
        layout.addWidget(self._send_btn)
        
        # é‡æ–°å¼€å§‹æŒ‰é’®
        self._reset_btn = QPushButton("ğŸ”„")
        self._reset_btn.setFixedSize(45, 45)
        self._reset_btn.setCursor(Qt.PointingHandCursor)
        self._reset_btn.setToolTip("é‡æ–°å¼€å§‹")
        self._reset_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #f97316, stop:1 #ea580c);
                border: none; border-radius: 22px; color: white; font-size: 18px;
            }
            QPushButton:hover { background: #c2410c; }
        """)
        self._reset_btn.clicked.connect(self._on_reset_click)
        layout.addWidget(self._reset_btn)
        
        # å…³é—­æŒ‰é’®
        close_btn = QPushButton("Ã—")
        close_btn.setFixedSize(30, 30)
        close_btn.setCursor(Qt.PointingHandCursor)
        close_btn.setStyleSheet("""
            QPushButton {
                background: rgba(255,255,255,0.1); border: none; border-radius: 15px;
                color: white; font-size: 18px;
            }
            QPushButton:hover { background: #ef4444; }
        """)
        close_btn.clicked.connect(self.close)
        layout.addWidget(close_btn)
        
        # æ³¨æ„ï¼šåœ¨Windowsä¸Šé€æ˜çª—å£ä½¿ç”¨é˜´å½±æ•ˆæœå¯èƒ½å¯¼è‡´UpdateLayeredWindowIndirecté”™è¯¯
        # å¦‚éœ€é˜´å½±æ•ˆæœï¼Œå¯å–æ¶ˆä¸‹é¢æ³¨é‡Š
        # shadow = QGraphicsDropShadowEffect()
        # shadow.setBlurRadius(20)
        # shadow.setColor(QColor(0, 0, 0, 100))
        # shadow.setOffset(0, 4)
        # self.setGraphicsEffect(shadow)

    def paintEvent(self, event):
        """ç»˜åˆ¶èƒŒæ™¯"""
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        path = QPainterPath()
        path.addRoundedRect(0, 0, self.width(), self.height(), 35, 35)
        gradient = QLinearGradient(0, 0, 0, self.height())
        gradient.setColorAt(0, QColor("#164270"))
        gradient.setColorAt(1, QColor("#24548C"))
        painter.fillPath(path, QBrush(gradient))
    
    def mousePressEvent(self, event):
        if event.button() == Qt.LeftButton:
            self._drag_pos = event.globalPos() - self.frameGeometry().topLeft()
    
    def mouseMoveEvent(self, event):
        if event.buttons() == Qt.LeftButton:
            self.move(event.globalPos() - self._drag_pos)

    def _start_agent(self):
        """å¯åŠ¨Agentçº¿ç¨‹"""
        def run():
            self._loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self._loop)
            self._agent = ElderlyAgent(self._signals)
            try:
                self._loop.run_until_complete(self._agent.initialize())
                self._loop.run_forever()
            except Exception as e:
                logger.error(f"Agenté”™è¯¯: {e}")
            finally:
                if self._agent:
                    self._loop.run_until_complete(self._agent.close())
                self._loop.close()
        
        self._agent_thread = threading.Thread(target=run, daemon=True)
        self._agent_thread.start()

    def _on_req_click(self):
        """éœ€æ±‚æŒ‰é’®ç‚¹å‡» - å¼€å§‹/åœæ­¢å½•éŸ³"""
        if self._is_processing:
            return
        
        if not self._is_recording:
            # å¼€å§‹å½•éŸ³
            self._is_recording = True
            self._current_input_type = "requirement"
            self._req_btn.setText("â¹åœæ­¢")
            self._req_btn.setStyleSheet("""
                QPushButton {
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FF5F6D, stop:1 #FFC371);
                    border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
                }
            """)
            self._ask_btn.setEnabled(False)
            self._input.setPlaceholderText("æ­£åœ¨å½•éŸ³...ç‚¹å‡»åœæ­¢ç»“æŸ")
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(self._agent.start_recording(), self._loop)
        else:
            # åœæ­¢å½•éŸ³
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(
                    self._agent.stop_recording("requirement"), self._loop
                )

    def _on_ask_click(self):
        """æé—®æŒ‰é’®ç‚¹å‡» - å¼€å§‹/åœæ­¢å½•éŸ³"""
        if self._is_processing:
            return
        
        if not self._is_recording:
            # å¼€å§‹å½•éŸ³
            self._is_recording = True
            self._current_input_type = "question"
            self._ask_btn.setText("â¹åœæ­¢")
            self._ask_btn.setStyleSheet("""
                QPushButton {
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FF5F6D, stop:1 #FFC371);
                    border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
                }
            """)
            self._req_btn.setEnabled(False)
            self._input.setPlaceholderText("æ­£åœ¨å½•éŸ³...ç‚¹å‡»åœæ­¢ç»“æŸ")
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(self._agent.start_recording(), self._loop)
        else:
            # åœæ­¢å½•éŸ³
            if self._agent and self._loop:
                asyncio.run_coroutine_threadsafe(
                    self._agent.stop_recording("question"), self._loop
                )

    def _on_recording_done(self, text: str, input_type: str):
        """å½•éŸ³å®Œæˆ"""
        self._is_recording = False
        
        # æ¢å¤æŒ‰é’®çŠ¶æ€
        self._req_btn.setText("ğŸ¤éœ€æ±‚")
        self._req_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFB75E, stop:1 #ED8F03);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFC988, stop:1 #FF9D00); }
        """)
        self._req_btn.setEnabled(True)
        
        self._ask_btn.setText("â“æé—®")
        self._ask_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #667eea, stop:1 #764ba2);
                border: none; border-radius: 10px; color: white; font-size: 14px; font-weight: bold;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #7c94f4, stop:1 #8b5fbf); }
        """)
        self._ask_btn.setEnabled(True)
        
        self._input.setPlaceholderText("è¾“å…¥éœ€æ±‚æˆ–é—®é¢˜...")
        
        if text:
            self._input.setText(text)
            # æ ¹æ®è¾“å…¥ç±»å‹å¤„ç†
            if input_type == "requirement":
                self._process_requirement()
            else:
                self._process_question()

    def _on_send(self):
        """å‘é€æŒ‰é’® - é»˜è®¤ä½œä¸ºéœ€æ±‚å¤„ç†"""
        self._process_requirement()

    def _process_requirement(self):
        """å¤„ç†éœ€æ±‚"""
        if self._is_processing:
            return
        text = self._input.text().strip()
        if not text:
            return
        self._input.clear()
        self._is_processing = True
        self._set_buttons_enabled(False)
        
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.process_requirement(text), self._loop)

    def _process_question(self):
        """å¤„ç†æé—®"""
        if self._is_processing:
            return
        text = self._input.text().strip()
        if not text:
            return
        self._input.clear()
        self._is_processing = True
        self._set_buttons_enabled(False)
        
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.process_question(text), self._loop)

    def _on_reset_click(self):
        """é‡æ–°å¼€å§‹æŒ‰é’®ç‚¹å‡»"""
        if self._is_recording:
            return
        self._input.clear()
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.reset_flow(), self._loop)

    def _on_reset_done(self):
        """é‡ç½®å®Œæˆ"""
        self._is_processing = False
        self._set_buttons_enabled(True)
        self._input.setPlaceholderText("è¯·è¯´å‡ºæ‚¨çš„éœ€æ±‚...")

    def _set_buttons_enabled(self, enabled: bool):
        """è®¾ç½®æŒ‰é’®å¯ç”¨çŠ¶æ€"""
        self._req_btn.setEnabled(enabled)
        self._ask_btn.setEnabled(enabled)
        self._send_btn.setEnabled(enabled)
        self._input.setEnabled(enabled)

    def _on_status_changed(self, status: str):
        """çŠ¶æ€å˜åŒ–"""
        self._input.setPlaceholderText(status)
    
    def _on_processing_done(self):
        """å¤„ç†å®Œæˆ"""
        self._is_processing = False
        self._set_buttons_enabled(True)
        self._input.setPlaceholderText("è¾“å…¥éœ€æ±‚æˆ–é—®é¢˜...")
    
    def closeEvent(self, event):
        """å…³é—­"""
        if self._loop:
            self._loop.call_soon_threadsafe(self._loop.stop)
        event.accept()


def main():
    logger.remove()
    logger.add(sys.stderr, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>")
    
    app = QApplication(sys.argv)
    app.setFont(QFont("Microsoft YaHei", 12))
    
    window = SimpleAssistantUI()
    window.show()
    
    sys.exit(app.exec_())


if __name__ == '__main__':
    main()
