"""
æ™ºèƒ½åŠ©æ‰‹æ¡Œé¢åº”ç”¨ - ç®€æ´ç‰ˆ
é›†æˆè¯­éŸ³è¾“å…¥/è¾“å‡ºã€ä»»åŠ¡æ‰§è¡ŒåŠŸèƒ½
"""
import sys
import asyncio
import threading
from PyQt5.QtWidgets import (QApplication, QWidget, QHBoxLayout, QVBoxLayout,
                             QLabel, QPushButton, QLineEdit, QGraphicsDropShadowEffect)
from PyQt5.QtCore import Qt, QPoint, pyqtSignal, QObject
from PyQt5.QtGui import QFont, QColor, QPainter, QPainterPath, QBrush, QLinearGradient

from src.config import config
from src.models.intent import Intent
from src.models.task import Task, TaskStatus, TaskPlan
from src.models.session import UserProfile
from src.models.knowledge import KnowledgeGraph
from src.services.llm_service import LLMService
from src.services.vision_service import VisionService, VLConfig, ScreenAnalysis
from src.services.planner_service import PlannerService
from src.services.safety_service import SafetyService
from src.services.executor_service import ExecutorService
from src.services.embedding_service import EmbeddingService
from src.services.tts_service import TTSService
from src.services.asr_service import ASRService, ASRConfig, AudioCapture
from src.knowledge.rag_service import RAGService
from loguru import logger


class SignalBridge(QObject):
    """Qtä¿¡å·æ¡¥æ¥å™¨ï¼Œç”¨äºçº¿ç¨‹é—´é€šä¿¡"""
    status_changed = pyqtSignal(str)
    message_received = pyqtSignal(str)
    recording_done = pyqtSignal(str)
    processing_done = pyqtSignal()


class ElderlyAgent:
    """è€å¹´äººåŠ©æ‰‹Agent"""
    
    def __init__(self, signals: SignalBridge):
        self._signals = signals
        self._llm = None
        self._vision = None
        self._planner = None
        self._safety = None
        self._executor = None
        self._embedding = None
        self._rag = None
        self._knowledge_graph = None
        self._tts = None
        self._asr = None
        self._audio_capture = None
        self._user_profile = None
        self._current_plan = None
        self._current_intent = None
        self._idle_timeout = 30  # æ— åŠ¨ä½œè¶…æ—¶ç§’æ•°
        self._last_action_time = None
        self._idle_check_task = None

    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
        self._signals.status_changed.emit("åˆå§‹åŒ–è¯­éŸ³æœåŠ¡...")
        self._tts = TTSService()
        await self._tts.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«...")
        asr_config = ASRConfig(
            project_id=config.asr.project_id,
            easyllm_id=config.asr.easyllm_id,
            api_key=config.asr.api_key,
        )
        self._asr = ASRService(asr_config)
        await self._asr.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–æ„å›¾ç†è§£...")
        self._llm = LLMService()
        await self._llm.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è§†è§‰æœåŠ¡...")
        vl_config = VLConfig(
            api_key=config.api.api_key,
            model_light=config.api.vl_model_light,
            model_heavy=config.api.vl_model_heavy,
        )
        self._vision = VisionService(vl_config)
        await self._vision.initialize()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–è§„åˆ’æœåŠ¡...")
        self._planner = PlannerService()
        await self._planner.initialize()
        
        self._safety = SafetyService()
        
        self._signals.status_changed.emit("åˆå§‹åŒ–çŸ¥è¯†æœåŠ¡...")
        self._embedding = EmbeddingService()
        await self._embedding.initialize()
        
        self._knowledge_graph = KnowledgeGraph()
        self._rag = RAGService()
        await self._rag.initialize(
            embedding_service=self._embedding,
            knowledge_graph=self._knowledge_graph,
        )
        self._planner.set_rag_service(self._rag)
        
        self._signals.status_changed.emit("åˆå§‹åŒ–æ‰§è¡ŒæœåŠ¡...")
        self._executor = ExecutorService()
        self._executor.set_vision_service(self._vision)
        self._executor.set_planner_service(self._planner)
        await self._executor.initialize()
        
        self._user_profile = UserProfile(
            name="ç”¨æˆ·",
            family_mapping={"è€äºŒ": "å¼ å°æ˜", "é—ºå¥³": "å¼ å°çº¢"},
            frequent_contacts=["å¼ å°æ˜", "å¼ å°çº¢"],
        )
        
        self._signals.status_changed.emit("å‡†å¤‡å°±ç»ª")
        await self._tts.speak_welcome()
        
        # å¯åŠ¨ç©ºé—²æ£€æµ‹
        self._last_action_time = asyncio.get_event_loop().time()
        self._idle_check_task = asyncio.create_task(self._check_idle())

    async def _check_idle(self):
        """æ£€æµ‹ç”¨æˆ·æ˜¯å¦é•¿æ—¶é—´æ— åŠ¨ä½œ"""
        while True:
            await asyncio.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
            if self._last_action_time:
                elapsed = asyncio.get_event_loop().time() - self._last_action_time
                if elapsed >= self._idle_timeout:
                    await self._tts.speak("æ‚¨å¥½ï¼Œéœ€è¦æˆ‘å¸®æ‚¨åšä»€ä¹ˆå—ï¼Ÿ")
                    self._last_action_time = asyncio.get_event_loop().time()  # é‡ç½®è®¡æ—¶
    
    def _reset_idle_timer(self):
        """é‡ç½®ç©ºé—²è®¡æ—¶å™¨"""
        self._last_action_time = asyncio.get_event_loop().time()

    async def close(self):
        """å…³é—­æœåŠ¡"""
        if self._idle_check_task:
            self._idle_check_task.cancel()
        for svc in [self._asr, self._tts, self._llm, self._vision, 
                    self._planner, self._executor, self._embedding]:
            if svc:
                await svc.close()


    async def voice_input(self, duration: float = 5.0):
        """è¯­éŸ³è¾“å…¥"""
        self._reset_idle_timer()
        try:
            await self._tts.speak("è¯·è¯´è¯")
            self._audio_capture = AudioCapture(sample_rate=config.asr.sample_rate)
            self._audio_capture.start()
            
            audio_data = b""
            start_time = asyncio.get_event_loop().time()
            async for chunk in self._audio_capture.get_audio_stream():
                audio_data += chunk
                if asyncio.get_event_loop().time() - start_time >= duration:
                    break
            
            self._audio_capture.stop()
            
            if audio_data:
                self._signals.status_changed.emit("è¯†åˆ«ä¸­...")
                result = await self._asr.recognize_audio(audio_data)
                text = result.text.strip() if result.text else ""
                if text:
                    await self._tts.speak(f"æ‚¨è¯´çš„æ˜¯ï¼š{text}")
                self._signals.recording_done.emit(text)
            else:
                self._signals.recording_done.emit("")
        except Exception as e:
            logger.error(f"è¯­éŸ³è¾“å…¥å¤±è´¥: {e}")
            self._signals.recording_done.emit("")

    async def process_input(self, user_input: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        self._reset_idle_timer()
        try:
            self._signals.status_changed.emit("å®‰å…¨æ£€æŸ¥...")
            
            safety_result = self._safety.check_text_safety(user_input)
            if not safety_result.is_safe and safety_result.blocked_reason:
                await self._tts.speak(f"å®‰å…¨è­¦å‘Šï¼š{safety_result.blocked_reason}")
                self._signals.processing_done.emit()
                return
            
            self._signals.status_changed.emit("ç†è§£æ„å›¾...")
            intent = await self._llm.understand_intent(user_input, self._user_profile)
            self._current_intent = intent
            
            if intent.confidence.is_low:
                await self._tts.speak("æˆ‘ä¸å¤ªç¡®å®šæ‚¨æƒ³åšä»€ä¹ˆï¼Œèƒ½å†è¯´è¯¦ç»†ä¸€ç‚¹å—ï¼Ÿ")
                self._signals.processing_done.emit()
                return
            
            self._signals.status_changed.emit("åˆ†æå±å¹•...")
            screenshot, original_size = await self._vision.capture_screen()
            
            if not screenshot:
                await self._tts.speak("æˆªå±å¤±è´¥")
                self._signals.processing_done.emit()
                return
            
            screen_state = await self._vision.analyze_screen_state(
                screenshot, user_intent=intent.normalized_text or user_input
            )
            
            screen_analysis = ScreenAnalysis(
                app_name=screen_state.app_name,
                screen_type=screen_state.screen_state,
                description=screen_state.description,
                suggested_actions=[screen_state.suggested_action] if screen_state.suggested_action else [],
                warnings=screen_state.warnings,
            )
            
            self._signals.status_changed.emit("ç”Ÿæˆè®¡åˆ’...")
            plan = await self._planner.create_plan(intent=intent, screen_analysis=screen_analysis)
            self._current_plan = plan
            
            if not plan.steps:
                await self._tts.speak("æŠ±æ­‰ï¼Œæˆ‘ä¸ç¡®å®šè¯¥æ€ä¹ˆå¸®æ‚¨")
                self._signals.processing_done.emit()
                return
            
            from src.models.action import ActionType
            if len(plan.steps) == 1 and plan.steps[0].action and plan.steps[0].action.action_type == ActionType.DONE:
                msg = plan.steps[0].friendly_instruction or "ä»»åŠ¡å·²å®Œæˆ"
                await self._tts.speak_success(msg)
                self._signals.status_changed.emit("å®Œæˆ")
                self._signals.processing_done.emit()
                return
            
            # ä¸æ’­æŠ¥æ•´ä½“è®¡åˆ’ï¼Œç›´æ¥å¼€å§‹æ‰§è¡Œ
            self._signals.status_changed.emit("æ‰§è¡Œä¸­...")
            await self._tts.speak("å¥½çš„ï¼Œæˆ‘æ¥å¸®æ‚¨æ“ä½œ")
            
            # é€æ­¥æ‰§è¡Œå¹¶æ’­æŠ¥æ¯ä¸€æ­¥
            total_steps = len(plan.steps)
            for i, step in enumerate(plan.steps):
                self._reset_idle_timer()
                step_msg = step.friendly_instruction or step.description
                # æ’­æŠ¥å½“å‰æ­¥éª¤
                await self._tts.speak(f"ç¬¬{i+1}æ­¥ï¼Œ{step_msg}")
                self._signals.status_changed.emit(f"æ­¥éª¤ {i+1}/{total_steps}")
            
            task = await self._executor.execute_task(self._current_intent, plan=self._current_plan)
            
            if task.status == TaskStatus.COMPLETED:
                await self._tts.speak_success("ä»»åŠ¡å®Œæˆï¼")
                self._signals.status_changed.emit("å®Œæˆ")
            else:
                await self._tts.speak("ä»»åŠ¡æœªå®Œæˆï¼Œæ‚¨å¯ä»¥å‘Šè¯‰æˆ‘é‡åˆ°äº†ä»€ä¹ˆé—®é¢˜")
                self._signals.status_changed.emit("æœªå®Œæˆ")
            
        except Exception as e:
            logger.error(f"å¤„ç†å‡ºé”™: {e}")
            await self._tts.speak_error(str(e))
            self._signals.status_changed.emit("å‡ºé”™")
        finally:
            self._reset_idle_timer()
            self._signals.processing_done.emit()


class SimpleAssistantUI(QWidget):
    """ç®€æ´åŠ©æ‰‹ç•Œé¢"""
    
    def __init__(self):
        super().__init__()
        self._drag_pos = QPoint()
        self._is_recording = False
        self._is_processing = False
        self._signals = SignalBridge()
        self._agent = None
        self._loop = None
        self._agent_thread = None
        
        self._signals.status_changed.connect(self._on_status_changed)
        self._signals.recording_done.connect(self._on_recording_done)
        self._signals.processing_done.connect(self._on_processing_done)
        
        self.initUI()
        self._start_agent()
    
    def initUI(self):
        """åˆå§‹åŒ–ç•Œé¢"""
        self.setWindowFlags(Qt.FramelessWindowHint | Qt.WindowStaysOnTopHint | Qt.Tool)
        self.setAttribute(Qt.WA_TranslucentBackground)
        self.setFixedSize(400, 70)
        
        # å±å¹•é¡¶éƒ¨å±…ä¸­
        screen = QApplication.primaryScreen().geometry()
        self.move((screen.width() - 400) // 2, 20)
        
        layout = QHBoxLayout(self)
        layout.setContentsMargins(15, 10, 15, 10)
        layout.setSpacing(10)
        
        # è¯­éŸ³æŒ‰é’®
        self._voice_btn = QPushButton("ğŸ¤")
        self._voice_btn.setFixedSize(50, 50)
        self._voice_btn.setCursor(Qt.PointingHandCursor)
        self._voice_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFB75E, stop:1 #ED8F03);
                border: none; border-radius: 25px; color: white; font-size: 24px;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFC988, stop:1 #FF9D00); }
        """)
        self._voice_btn.clicked.connect(self._on_voice_click)
        layout.addWidget(self._voice_btn)
        
        # è¾“å…¥æ¡†
        self._input = QLineEdit()
        self._input.setPlaceholderText("è¾“å…¥æˆ–ç‚¹å‡»éº¦å…‹é£è¯´è¯...")
        self._input.setStyleSheet("""
            QLineEdit {
                background: rgba(255,255,255,0.15); border: 1px solid rgba(255,255,255,0.3);
                border-radius: 20px; color: white; font-size: 16px; padding: 10px 15px;
            }
        """)
        self._input.returnPressed.connect(self._on_send)
        layout.addWidget(self._input)
        
        # å‘é€æŒ‰é’®
        self._send_btn = QPushButton("â¤")
        self._send_btn.setFixedSize(50, 50)
        self._send_btn.setCursor(Qt.PointingHandCursor)
        self._send_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #4ade80, stop:1 #22c55e);
                border: none; border-radius: 25px; color: white; font-size: 20px;
            }
            QPushButton:hover { background: #16a34a; }
        """)
        self._send_btn.clicked.connect(self._on_send)
        layout.addWidget(self._send_btn)
        
        # å…³é—­æŒ‰é’®
        close_btn = QPushButton("Ã—")
        close_btn.setFixedSize(30, 30)
        close_btn.setCursor(Qt.PointingHandCursor)
        close_btn.setStyleSheet("""
            QPushButton {
                background: rgba(255,255,255,0.1); border: none; border-radius: 15px;
                color: white; font-size: 18px;
            }
            QPushButton:hover { background: #ef4444; }
        """)
        close_btn.clicked.connect(self.close)
        layout.addWidget(close_btn)
        
        # é˜´å½±
        shadow = QGraphicsDropShadowEffect()
        shadow.setBlurRadius(20)
        shadow.setColor(QColor(0, 0, 0, 100))
        shadow.setOffset(0, 4)
        self.setGraphicsEffect(shadow)
    
    def paintEvent(self, event):
        """ç»˜åˆ¶èƒŒæ™¯"""
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        path = QPainterPath()
        path.addRoundedRect(0, 0, self.width(), self.height(), 35, 35)
        gradient = QLinearGradient(0, 0, 0, self.height())
        gradient.setColorAt(0, QColor("#164270"))
        gradient.setColorAt(1, QColor("#24548C"))
        painter.fillPath(path, QBrush(gradient))
    
    def mousePressEvent(self, event):
        if event.button() == Qt.LeftButton:
            self._drag_pos = event.globalPos() - self.frameGeometry().topLeft()
    
    def mouseMoveEvent(self, event):
        if event.buttons() == Qt.LeftButton:
            self.move(event.globalPos() - self._drag_pos)

    
    def _start_agent(self):
        """å¯åŠ¨Agentçº¿ç¨‹"""
        def run():
            self._loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self._loop)
            self._agent = ElderlyAgent(self._signals)
            try:
                self._loop.run_until_complete(self._agent.initialize())
                self._loop.run_forever()
            except Exception as e:
                logger.error(f"Agenté”™è¯¯: {e}")
            finally:
                if self._agent:
                    self._loop.run_until_complete(self._agent.close())
                self._loop.close()
        
        self._agent_thread = threading.Thread(target=run, daemon=True)
        self._agent_thread.start()
    
    def _on_voice_click(self):
        """è¯­éŸ³æŒ‰é’®ç‚¹å‡»"""
        if self._is_processing or self._is_recording:
            return
        self._is_recording = True
        self._voice_btn.setText("ğŸ”´")
        self._voice_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FF5F6D, stop:1 #FFC371);
                border: none; border-radius: 25px; color: white; font-size: 24px;
            }
        """)
        self._input.setPlaceholderText("æ­£åœ¨å½•éŸ³...")
        
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.voice_input(), self._loop)
    
    def _on_recording_done(self, text: str):
        """å½•éŸ³å®Œæˆ"""
        self._is_recording = False
        self._voice_btn.setText("ğŸ¤")
        self._voice_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFB75E, stop:1 #ED8F03);
                border: none; border-radius: 25px; color: white; font-size: 24px;
            }
            QPushButton:hover { background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #FFC988, stop:1 #FF9D00); }
        """)
        self._input.setPlaceholderText("è¾“å…¥æˆ–ç‚¹å‡»éº¦å…‹é£è¯´è¯...")
        
        if text:
            self._input.setText(text)
            self._on_send()
    
    def _on_send(self):
        """å‘é€"""
        if self._is_processing:
            return
        text = self._input.text().strip()
        if not text:
            return
        self._input.clear()
        self._is_processing = True
        self._input.setEnabled(False)
        self._send_btn.setEnabled(False)
        
        if self._agent and self._loop:
            asyncio.run_coroutine_threadsafe(self._agent.process_input(text), self._loop)
    
    def _on_status_changed(self, status: str):
        """çŠ¶æ€å˜åŒ–"""
        self._input.setPlaceholderText(status)
    
    def _on_processing_done(self):
        """å¤„ç†å®Œæˆ"""
        self._is_processing = False
        self._input.setEnabled(True)
        self._send_btn.setEnabled(True)
        self._input.setPlaceholderText("è¾“å…¥æˆ–ç‚¹å‡»éº¦å…‹é£è¯´è¯...")
    
    def closeEvent(self, event):
        """å…³é—­"""
        if self._loop:
            self._loop.call_soon_threadsafe(self._loop.stop)
        event.accept()


def main():
    logger.remove()
    logger.add(sys.stderr, level="INFO", format="<dim>{time:HH:mm:ss}</dim> | <level>{message}</level>")
    
    app = QApplication(sys.argv)
    app.setFont(QFont("Microsoft YaHei", 12))
    
    window = SimpleAssistantUI()
    window.show()
    
    sys.exit(app.exec_())


if __name__ == '__main__':
    main()
